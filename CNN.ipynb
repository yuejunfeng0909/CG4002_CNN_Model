{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process dataset\n",
    "Extract data from the txt file for each user. We only extract the data for the time frame where the user is doing one action, not across different actions. Then we segment the data into 2 seconds window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file loader\n",
    "def load_data(file):\n",
    "    data = pd.read_csv(file, header=None, delim_whitespace = True)\n",
    "    return data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset initialized with size: 4429\n",
      "Class 0 has 1161 samples\n",
      "Class 1 has 1078 samples\n",
      "Class 2 has 979 samples\n",
      "Class 3 has 1211 samples\n"
     ]
    }
   ],
   "source": [
    "N_classes = 4\n",
    "window_size = 100   # 50Hz, 100 samples = 2s of movement\n",
    "classes = ('WALKING', 'WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS', \n",
    "            'SITTING', 'STANDING', 'LAYING', 'STAND_TO_SIT', 'SIT_TO_STAND', \n",
    "            'SIT_TO_LIE', 'LIE_TO_SIT', 'STAND_TO_LIE', 'LIE_TO_STAND')[:N_classes]\n",
    "\n",
    "\n",
    "def load_dataset(data_dir):\n",
    "    raw_labels = open(data_dir + \"/labels.txt\", \"r\")\n",
    "    dataset_x = []\n",
    "    dataset_y = []\n",
    "    current_exp, current_user = 0, 0\n",
    "    acc_current_file_lines = []\n",
    "    gyro_current_file_lines = []\n",
    "    for line in raw_labels:\n",
    "        # get the experiment and user data\n",
    "        line_split = list(map(int,line.split()))\n",
    "\n",
    "        # filter out the transition movements\n",
    "        if line_split[2] > N_classes:\n",
    "            continue\n",
    "\n",
    "        # open new file if the current experiment and user are different from the previous run\n",
    "        if line_split[0] != current_exp or line_split[1] != current_user:\n",
    "            current_exp, current_user = line_split[0], line_split[1]\n",
    "\n",
    "            # Get the accelerometer data\n",
    "            # with open(data_dir + \"/acc_exp\" + str.zfill(str(current_exp), 2) + \"_user\" + str.zfill(str(current_user), 2) + \".txt\", \"r\") as accelerometer_file:\n",
    "            #     # print(\"Opened file: \" + current_file.name)\n",
    "            #     acc_current_file_lines = []\n",
    "            #     for file_line in accelerometer_file:\n",
    "            #         acc_current_file_lines.append(list(map(float, file_line.split())))\n",
    "            acc_file_name = data_dir + \"/acc_exp\" + str.zfill(str(current_exp), 2) + \"_user\" + str.zfill(str(current_user), 2) + \".txt\"\n",
    "            acc_current_file_lines = load_data(acc_file_name)\n",
    "\n",
    "            # Get the gyro data\n",
    "            # with open(data_dir + \"/gyro_exp\" + str.zfill(str(current_exp), 2) + \"_user\" + str.zfill(str(current_user), 2) + \".txt\", \"r\") as gyroscope_file:\n",
    "            #     # print(\"Opened file: \" + current_file.name)\n",
    "            #     gyro_current_file_lines = []\n",
    "            #     for file_line in gyroscope_file:\n",
    "            #         gyro_current_file_lines.append(list(map(float, file_line.split())))\n",
    "            gyro_file_name = data_dir + \"/gyro_exp\" + str.zfill(str(current_exp), 2) + \"_user\" + str.zfill(str(current_user), 2) + \".txt\"\n",
    "            gyro_current_file_lines = load_data(gyro_file_name)\n",
    "            \n",
    "        \n",
    "        # get the label, start and end indices\n",
    "        label, start, end = line_split[2:5]\n",
    "        label -= 1 # convert to 0-indexed\n",
    "\n",
    "        # sliding window\n",
    "        for i in range(start, end - window_size, window_size):\n",
    "            # calculate fft for the window\n",
    "            acc_window = acc_current_file_lines[i:i+window_size]\n",
    "            gyro_window = gyro_current_file_lines[i:i+window_size]\n",
    "            inputs = np.concatenate((acc_window, gyro_window), axis=1)\n",
    "            inputs = np.float32(np.transpose(inputs))\n",
    "            dataset_x.append(inputs)\n",
    "            dataset_y.append(label)\n",
    "\n",
    "    raw_labels.close()\n",
    "\n",
    "    print(\"Dataset initialized with size: \" + str(len(dataset_y)))\n",
    "    for i in range(N_classes):\n",
    "        print(\"Class \" + str(i) + \" has \" + str(dataset_y.count(i)) + \" samples\")\n",
    "    \n",
    "    dataset_y = to_categorical(dataset_y)\n",
    "    return np.array(dataset_x), np.array(dataset_y)\n",
    "dataset_x, dataset_y = load_dataset(\"HAPT Data Set/RawData\")\n",
    "train_x, test_x, train_y, test_y = train_test_split(dataset_x, dataset_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  6/111 [>.............................] - ETA: 1s - loss: 1.2174 - accuracy: 0.4010 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-04 13:06:34.197569: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/111 [============================>.] - ETA: 0s - loss: 0.4750 - accuracy: 0.8000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-04 13:06:35.700180: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 2s 15ms/step - loss: 0.4731 - accuracy: 0.8010 - val_loss: 0.2028 - val_accuracy: 0.9221 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "111/111 [==============================] - 2s 14ms/step - loss: 0.1624 - accuracy: 0.9486 - val_loss: 0.0966 - val_accuracy: 0.9673 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 0.0538 - accuracy: 0.9831 - val_loss: 0.0617 - val_accuracy: 0.9797 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 0.0266 - accuracy: 0.9915 - val_loss: 0.0352 - val_accuracy: 0.9887 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "111/111 [==============================] - 2s 14ms/step - loss: 0.0187 - accuracy: 0.9952 - val_loss: 0.0254 - val_accuracy: 0.9944 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "111/111 [==============================] - 2s 15ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 0.0191 - val_accuracy: 0.9876 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.0164 - val_accuracy: 0.9944 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "111/111 [==============================] - 2s 14ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 0.9977 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 6.5271e-04 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 0.9955 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "111/111 [==============================] - 2s 14ms/step - loss: 4.6413e-04 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9955 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 0.0251 - accuracy: 0.9921 - val_loss: 0.0502 - val_accuracy: 0.9865 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 0.0393 - accuracy: 0.9865 - val_loss: 0.0407 - val_accuracy: 0.9865 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 0.0159 - accuracy: 0.9946 - val_loss: 0.0069 - val_accuracy: 0.9989 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "111/111 [==============================] - 2s 14ms/step - loss: 0.0171 - accuracy: 0.9958 - val_loss: 0.0114 - val_accuracy: 0.9955 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 0.0077 - accuracy: 0.9972 - val_loss: 0.0252 - val_accuracy: 0.9887 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.0411 - val_accuracy: 0.9898 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0052 - val_accuracy: 0.9977 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 0.0015 - accuracy: 0.9992 - val_loss: 0.0025 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 3.7324e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9977 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 2.5569e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 1.2166e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 5.1375e-05 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 6.6720e-05 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 6.3677e-05 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 0.9989 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 2.8583e-05 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9989 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 0.0148 - accuracy: 0.9949 - val_loss: 0.0186 - val_accuracy: 0.9921 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 0.0373 - accuracy: 0.9887 - val_loss: 0.0086 - val_accuracy: 0.9966 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.0056 - val_accuracy: 0.9989 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0052 - val_accuracy: 0.9977 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 4.9791e-04 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 0.9977 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 7.4368e-04 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 0.9977 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 7.2281e-04 - accuracy: 0.9997 - val_loss: 0.0045 - val_accuracy: 0.9977 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "111/111 [==============================] - 2s 14ms/step - loss: 3.2150e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 3.5725e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 2.7265e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 3.4107e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 3.4392e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 3.7485e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-05\n",
      "Epoch 39/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 2.5052e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-06\n",
      "Epoch 40/100\n",
      "111/111 [==============================] - 2s 14ms/step - loss: 3.2566e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-06\n",
      "Epoch 41/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 4.1881e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-06\n",
      "Epoch 42/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 3.1516e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-06\n",
      "Epoch 43/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 2.7007e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-06\n",
      "Epoch 44/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 5.5642e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-07\n",
      "Epoch 45/100\n",
      "111/111 [==============================] - 2s 14ms/step - loss: 3.8924e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-07\n",
      "Epoch 46/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 3.9552e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-07\n",
      "Epoch 47/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 3.1848e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-07\n",
      "Epoch 48/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 2.7484e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-07\n",
      "Epoch 49/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 3.4383e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-08\n",
      "Epoch 50/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 3.2978e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-08\n",
      "Epoch 51/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 2.7046e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-08\n",
      "Epoch 52/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 3.9023e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-08\n",
      "Epoch 53/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 4.2266e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-08\n",
      "Epoch 54/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 3.4151e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-09\n",
      "Epoch 55/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 2.4952e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-09\n",
      "Epoch 56/100\n",
      "111/111 [==============================] - 2s 14ms/step - loss: 3.8338e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-09\n",
      "Epoch 57/100\n",
      "111/111 [==============================] - 2s 14ms/step - loss: 3.9074e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-09\n",
      "Epoch 58/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 4.3119e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-09\n",
      "Epoch 59/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 4.0493e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-10\n",
      "Epoch 60/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 3.4617e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-10\n",
      "Epoch 61/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 4.8588e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-10\n",
      "Epoch 62/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 3.5971e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-10\n",
      "Epoch 63/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 4.3577e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-10\n",
      "Epoch 64/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 4.6767e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-11\n",
      "Epoch 65/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 2.8461e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-11\n",
      "Epoch 66/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 2.7420e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-11\n",
      "Epoch 67/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 4.3643e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-11\n",
      "Epoch 68/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 1.9659e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-11\n",
      "Epoch 69/100\n",
      "111/111 [==============================] - 2s 14ms/step - loss: 3.1717e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-12\n",
      "Epoch 70/100\n",
      "111/111 [==============================] - 2s 14ms/step - loss: 2.5718e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-12\n",
      "Epoch 71/100\n",
      "111/111 [==============================] - 2s 14ms/step - loss: 2.5889e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-12\n",
      "Epoch 72/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 4.0410e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-12\n",
      "Epoch 73/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 3.6749e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-12\n",
      "Epoch 74/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 4.9674e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-13\n",
      "Epoch 75/100\n",
      "111/111 [==============================] - 2s 14ms/step - loss: 4.2811e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-13\n",
      "Epoch 76/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 3.5559e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-13\n",
      "Epoch 77/100\n",
      "111/111 [==============================] - 2s 14ms/step - loss: 3.1178e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-13\n",
      "Epoch 78/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 2.3103e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-13\n",
      "Epoch 79/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 4.0961e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-14\n",
      "Epoch 80/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 4.0284e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-14\n",
      "Epoch 81/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 4.6468e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-14\n",
      "Epoch 82/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 3.2919e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-14\n",
      "Epoch 83/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 2.7286e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-14\n",
      "Epoch 84/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 4.0036e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-15\n",
      "Epoch 85/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 4.6571e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-15\n",
      "Epoch 86/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 4.5982e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-15\n",
      "Epoch 87/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 3.1891e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-15\n",
      "Epoch 88/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 3.0849e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-15\n",
      "Epoch 89/100\n",
      "111/111 [==============================] - 2s 14ms/step - loss: 3.7970e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-16\n",
      "Epoch 90/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 3.0879e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-16\n",
      "Epoch 91/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 2.2765e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-16\n",
      "Epoch 92/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 3.7739e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-16\n",
      "Epoch 93/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 3.4739e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-16\n",
      "Epoch 94/100\n",
      "111/111 [==============================] - 2s 14ms/step - loss: 4.1437e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-17\n",
      "Epoch 95/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 3.9121e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-17\n",
      "Epoch 96/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 3.3219e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-17\n",
      "Epoch 97/100\n",
      "111/111 [==============================] - 2s 14ms/step - loss: 3.5678e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-17\n",
      "Epoch 98/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 3.2194e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-17\n",
      "Epoch 99/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 5.0357e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-18\n",
      "Epoch 100/100\n",
      "111/111 [==============================] - 1s 13ms/step - loss: 3.5100e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9977 - lr: 1.0000e-18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2c601d3d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(64, 6, activation='relu', input_shape=(6, 100), data_format='channels_first'))\n",
    "model.add(Conv1D(64, 6, activation='relu', data_format='channels_first'))\n",
    "model.add(Dropout(0.5)) # 50% dropout\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(N_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# checkpoint callback\n",
    "checkpoint_filepath = \"model_checkpoint/\"\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "# learning rate reduce on plateau callback\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=0)\n",
    "\n",
    "# early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Train the model\n",
    "def train_network(model, train_x, train_y, test_x, test_y):\n",
    "    verbose = 1 # 0 for no logging to stdout, 1 for progress bar logging, 2 for one log line per epoch.\n",
    "    epochs = 100\n",
    "    batch_size = 32\n",
    "    model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, validation_data=(test_x, test_y), callbacks = [model_checkpoint_callback, reduce_lr, early_stopping], verbose=verbose)\n",
    "    _, accuracy = model.evaluate(test_x, test_y, batch_size=batch_size, verbose=0)\n",
    "    return model\n",
    "\n",
    "model = train_network(model, train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'spines'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/yuejunfeng/Documents/NUS_Y3S1/CG4002/sw_model/CNN.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yuejunfeng/Documents/NUS_Y3S1/CG4002/sw_model/CNN.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m y_prediction \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(model\u001b[39m.\u001b[39mpredict(test_x), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yuejunfeng/Documents/NUS_Y3S1/CG4002/sw_model/CNN.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m result \u001b[39m=\u001b[39m confusion_matrix(np\u001b[39m.\u001b[39margmax(test_y, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), y_prediction)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yuejunfeng/Documents/NUS_Y3S1/CG4002/sw_model/CNN.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m sns\u001b[39m.\u001b[39;49mheatmap(result, annot\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, fmt\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39md\u001b[39;49m\u001b[39m\"\u001b[39;49m, ax\u001b[39m=\u001b[39;49mclasses)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/capstone/lib/python3.9/site-packages/seaborn/_decorators.py:46\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m     37\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPass the following variable\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m as \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39mkeyword arg\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFrom version 0.12, the only valid positional argument \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     )\n\u001b[1;32m     45\u001b[0m kwargs\u001b[39m.\u001b[39mupdate({k: arg \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args)})\n\u001b[0;32m---> 46\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/capstone/lib/python3.9/site-packages/seaborn/matrix.py:553\u001b[0m, in \u001b[0;36mheatmap\u001b[0;34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, linewidths, linecolor, cbar, cbar_kws, cbar_ax, square, xticklabels, yticklabels, mask, ax, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[39mif\u001b[39;00m square:\n\u001b[1;32m    552\u001b[0m     ax\u001b[39m.\u001b[39mset_aspect(\u001b[39m\"\u001b[39m\u001b[39mequal\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 553\u001b[0m plotter\u001b[39m.\u001b[39;49mplot(ax, cbar_ax, kwargs)\n\u001b[1;32m    554\u001b[0m \u001b[39mreturn\u001b[39;00m ax\n",
      "File \u001b[0;32m/opt/anaconda3/envs/capstone/lib/python3.9/site-packages/seaborn/matrix.py:293\u001b[0m, in \u001b[0;36m_HeatMapper.plot\u001b[0;34m(self, ax, cax, kws)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[39m\"\"\"Draw the heatmap on the provided Axes.\"\"\"\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[39m# Remove all the Axes spines\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m despine(ax\u001b[39m=\u001b[39;49max, left\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, bottom\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    295\u001b[0m \u001b[39m# setting vmin/vmax in addition to norm is deprecated\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[39m# so avoid setting if norm is set\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnorm\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m kws:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/capstone/lib/python3.9/site-packages/seaborn/utils.py:265\u001b[0m, in \u001b[0;36mdespine\u001b[0;34m(fig, ax, top, right, left, bottom, offset, trim)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[39mfor\u001b[39;00m side \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mtop\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mright\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mbottom\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    263\u001b[0m     \u001b[39m# Toggle the spine objects\u001b[39;00m\n\u001b[1;32m    264\u001b[0m     is_visible \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mlocals\u001b[39m()[side]\n\u001b[0;32m--> 265\u001b[0m     ax_i\u001b[39m.\u001b[39;49mspines[side]\u001b[39m.\u001b[39mset_visible(is_visible)\n\u001b[1;32m    266\u001b[0m     \u001b[39mif\u001b[39;00m offset \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m is_visible:\n\u001b[1;32m    267\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'spines'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.load_weights(checkpoint_filepath)\n",
    "y_prediction = np.argmax(model.predict(test_x), axis=1)\n",
    "result = confusion_matrix(np.argmax(test_y, axis=1), y_prediction)\n",
    "sns.heatmap(result, annot=True, fmt=\"d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('capstone')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f82d4ec2f4e1a7949fc551b5039d8b80c5fc6c2b366144cfac1fa6211cdc80ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
