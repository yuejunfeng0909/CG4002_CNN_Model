{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, Conv1D, MaxPooling1D, Softmax\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.backend import clear_session\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process dataset\n",
    "Extract data from the txt file for each user. We only extract the data for the time frame where the user is doing one action, not across different actions. Then we segment the data into 2 seconds window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file loader\n",
    "from os.path import isfile\n",
    "\n",
    "def load_data(file):\n",
    "    data = pd.read_csv(file, header=None)\n",
    "    return data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from Dataset/user0\n",
      "Loaded 15 shield files\n",
      "Loaded 15 reload files\n",
      "Loaded 15 grenade files\n",
      "Loaded 20 final files\n",
      "Loading data from Dataset/user1\n",
      "Loaded 20 shield files\n",
      "Loaded 15 reload files\n",
      "Loaded 20 grenade files\n",
      "Loaded 20 final files\n",
      "Loading data from Dataset/user2\n",
      "Loaded 20 shield files\n",
      "Loaded 13 reload files\n",
      "Loaded 14 grenade files\n",
      "Loaded 20 final files\n",
      "Loading data from Dataset/user3\n",
      "Loaded 20 shield files\n",
      "Loaded 14 reload files\n",
      "Loaded 20 grenade files\n",
      "Loaded 20 final files\n",
      "Dataset initialized with size: 281\n",
      "Class 0 has 75 samples\n",
      "Class 1 has 57 samples\n",
      "Class 2 has 69 samples\n",
      "Class 3 has 80 samples\n",
      "Dataset size after sliding window: 1098\n",
      "Class 0 has 248 samples\n",
      "Class 1 has 230 samples\n",
      "Class 2 has 286 samples\n",
      "Class 3 has 334 samples\n",
      "\n",
      "Test set distribution\n",
      "Class 0 has 75 samples\n",
      "Class 1 has 72 samples\n",
      "Class 2 has 59 samples\n",
      "Class 3 has 106 samples\n"
     ]
    }
   ],
   "source": [
    "window_size = 75   # 50Hz, 75 samples = 1.5s of movement\n",
    "window_stride = 25\n",
    "action_types = ('shield', 'reload', 'grenade', 'final')\n",
    "data_depth = 6\n",
    "\n",
    "dataset_users = [0, 1, 2, 3]\n",
    "\n",
    "# Function to load dataset\n",
    "def load_dataset(data_dir):\n",
    "    dataset_x = []\n",
    "    dataset_y = []\n",
    "    \n",
    "    for i in dataset_users:\n",
    "        user_data_dir = f\"{data_dir}/user{i}\"\n",
    "        print(f\"Loading data from {user_data_dir}\")\n",
    "    \n",
    "        for action_type in action_types:\n",
    "\n",
    "            for i in range(1, 100, 1):\n",
    "                # if file exists\n",
    "                if not isfile(user_data_dir + f\"/{action_type}{i}.csv\"):\n",
    "                    # print number of files loaded\n",
    "                    print(f\"Loaded {i-1} {action_type} files\")\n",
    "                    break\n",
    "                data = load_data(user_data_dir + f\"/{action_type}{i}.csv\")\n",
    "                dataset_x.append(np.int32(data))\n",
    "                dataset_y.append(action_types.index(action_type))\n",
    "\n",
    "    print(\"Dataset initialized with size: \" + str(len(dataset_y)))\n",
    "    for i in range(len(action_types)):\n",
    "        print(\"Class \" + str(i) + \" has \" + str(dataset_y.count(i)) + \" samples\")\n",
    "    dataset_y = to_categorical(dataset_y)\n",
    "    return dataset_x, np.array(dataset_y)\n",
    "\n",
    "def load_idle_dataset(data_dir):\n",
    "    dataset_x = []\n",
    "    dataset_y = []\n",
    "    \n",
    "    for i in dataset_users:\n",
    "        user_data_dir = f\"{data_dir}/user{i}\"\n",
    "        print(f\"Loading idle data from {user_data_dir}\")\n",
    "    \n",
    "        for i in range(1, 100, 1):\n",
    "            # if file exists\n",
    "            if not isfile(user_data_dir + f\"/idle{i}.csv\"):\n",
    "                break\n",
    "            data = load_data(user_data_dir + f\"/idle{i}.csv\")\n",
    "            dataset_x.append(data)\n",
    "            dataset_y.append([0.25, 0.25, 0.25, 0.25])\n",
    "\n",
    "    print(\"Idle dataset initialized with size: \" + str(len(dataset_y)))\n",
    "    return dataset_x, np.array(dataset_y)\n",
    "\n",
    "# To do sliding window on the data\n",
    "def sliding_window(data_X, data_Y, window_size, window_stride):\n",
    "    dataset_X_w_sliding = []\n",
    "    dataset_Y_w_sliding = []\n",
    "    for i in range(len(data_X)):\n",
    "        for j in range(0, len(data_X[i]) - window_size+1, window_stride):\n",
    "            dataset_X_w_sliding.append(data_X[i][j:j + window_size])\n",
    "            dataset_Y_w_sliding.append(data_Y[i])\n",
    "    return np.array(dataset_X_w_sliding), np.array(dataset_Y_w_sliding)\n",
    "\n",
    "\n",
    "# load dataset\n",
    "dataset_x, dataset_y = load_dataset(\"Dataset\")\n",
    "\n",
    "# split into train and test sets\n",
    "train_x, test_x, train_y, test_y = train_test_split(dataset_x, dataset_y, test_size=0.2, stratify = dataset_y, random_state=666)\n",
    "\n",
    "# backup test set for evaluation\n",
    "test_x_eval = copy.deepcopy(test_x)\n",
    "test_y_eval = copy.deepcopy(test_y)\n",
    "\n",
    "# combine the training data with idle data\n",
    "# dataset_x_idle, dataset_y_idle = load_idle_dataset(\"Dataset\")\n",
    "# train_x.extend(dataset_x_idle)\n",
    "# train_y = np.concatenate((train_y, dataset_y_idle), axis=0)\n",
    "\n",
    "# sliding window after train_test_split\n",
    "train_x, train_y = sliding_window(train_x, train_y, window_size, window_stride)\n",
    "test_x, test_y = sliding_window(test_x, test_y, window_size, window_stride)\n",
    "\n",
    "# print dataset size after sliding window\n",
    "print(\"Dataset size after sliding window: \" + str(len(train_y)))\n",
    "\n",
    "# calculate class weights\n",
    "class_weights = {}\n",
    "for i in range(len(action_types)):\n",
    "    class_weights[i] = 1 / dataset_y[:, i].sum()\n",
    "\n",
    "# print dataset disribution\n",
    "train_y_temp = np.argmax(train_y, axis=1)\n",
    "for i in range(len(action_types)):\n",
    "    print(\"Class \" + str(i) + \" has \" + str(train_y_temp.tolist().count(i)) + \" samples\")\n",
    "\n",
    "# backup test_x for c_sim and cosim\n",
    "test_x_copy = copy.deepcopy(test_x)\n",
    "\n",
    "# convert data from int16 to float32\n",
    "train_x, test_x = np.float32(train_x)/4096, np.float32(test_x)/4096\n",
    "# print(\"sample test x data: \" + str(test_x[0]))\n",
    "\n",
    "# summary of test dataset\n",
    "test = np.argmax(test_y, axis=1)\n",
    "print(\"\\nTest set distribution\")\n",
    "for i in range(len(action_types)):\n",
    "    print(\"Class \" + str(i) + \" has \" + str(test.tolist().count(i)) + \" samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 13, 32)            2912      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 13, 32)            0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 416)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 1668      \n",
      "                                                                 \n",
      " softmax (Softmax)           (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,580\n",
      "Trainable params: 4,580\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-01 00:34:27.750840: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conv1filters = 32\n",
    "conv1kernel = 15\n",
    "conv1stride = 5\n",
    "\n",
    "clear_session()\n",
    "model = Sequential()\n",
    "model.add(Conv1D(conv1filters, conv1kernel, strides=conv1stride, activation='relu', input_shape=(window_size, 6)))\n",
    "model.add(Dropout(0.5)) # 50% dropout\n",
    "# model.add(Conv1D(32, 10, activation='relu'))\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(len(action_types)))\n",
    "model.add(Softmax())\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# performance before training\n",
    "y_prediction = np.argmax(model.predict(test_x), axis=1)\n",
    "result = confusion_matrix(np.argmax(test_y, axis=1), y_prediction)\n",
    "sns.heatmap(result, annot=True, fmt=\"d\", xticklabels=action_types, yticklabels=action_types)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint callback\n",
    "checkpoint_filepath = \"model_checkpoint/\"\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "# learning rate reduce on plateau callback\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=50, min_lr=0)\n",
    "\n",
    "# early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=200, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/9 [==>...........................] - ETA: 2s - loss: 0.0234 - accuracy: 0.2109"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-01 00:34:29.157986: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 27ms/step - loss: 0.0229 - accuracy: 0.2668 - val_loss: 1.3487 - val_accuracy: 0.3141 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "7/9 [======================>.......] - ETA: 0s - loss: 0.0188 - accuracy: 0.3761"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-01 00:34:29.505491: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0188 - accuracy: 0.3798 - val_loss: 1.1848 - val_accuracy: 0.4968 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0163 - accuracy: 0.4882 - val_loss: 1.0535 - val_accuracy: 0.6154 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0143 - accuracy: 0.5911 - val_loss: 0.9392 - val_accuracy: 0.6859 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0130 - accuracy: 0.6311 - val_loss: 0.8356 - val_accuracy: 0.7564 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0114 - accuracy: 0.7040 - val_loss: 0.7425 - val_accuracy: 0.7724 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0104 - accuracy: 0.7213 - val_loss: 0.6708 - val_accuracy: 0.7692 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0095 - accuracy: 0.7450 - val_loss: 0.6151 - val_accuracy: 0.7821 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0088 - accuracy: 0.7541 - val_loss: 0.5745 - val_accuracy: 0.7917 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0084 - accuracy: 0.7678 - val_loss: 0.5471 - val_accuracy: 0.8077 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0079 - accuracy: 0.7805 - val_loss: 0.5183 - val_accuracy: 0.8141 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0074 - accuracy: 0.7905 - val_loss: 0.4987 - val_accuracy: 0.8205 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0072 - accuracy: 0.8060 - val_loss: 0.4831 - val_accuracy: 0.8141 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0070 - accuracy: 0.8115 - val_loss: 0.4745 - val_accuracy: 0.8205 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0066 - accuracy: 0.8279 - val_loss: 0.4562 - val_accuracy: 0.8269 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0065 - accuracy: 0.8270 - val_loss: 0.4426 - val_accuracy: 0.8365 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0062 - accuracy: 0.8260 - val_loss: 0.4361 - val_accuracy: 0.8526 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0060 - accuracy: 0.8361 - val_loss: 0.4240 - val_accuracy: 0.8590 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0059 - accuracy: 0.8260 - val_loss: 0.4154 - val_accuracy: 0.8526 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0057 - accuracy: 0.8415 - val_loss: 0.4044 - val_accuracy: 0.8494 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0056 - accuracy: 0.8415 - val_loss: 0.3963 - val_accuracy: 0.8558 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0055 - accuracy: 0.8488 - val_loss: 0.3942 - val_accuracy: 0.8654 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0056 - accuracy: 0.8443 - val_loss: 0.3873 - val_accuracy: 0.8686 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0054 - accuracy: 0.8443 - val_loss: 0.3870 - val_accuracy: 0.8718 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0052 - accuracy: 0.8488 - val_loss: 0.3847 - val_accuracy: 0.8526 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0052 - accuracy: 0.8497 - val_loss: 0.3739 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0050 - accuracy: 0.8597 - val_loss: 0.3591 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0049 - accuracy: 0.8652 - val_loss: 0.3550 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0047 - accuracy: 0.8643 - val_loss: 0.3530 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0049 - accuracy: 0.8597 - val_loss: 0.3531 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0048 - accuracy: 0.8634 - val_loss: 0.3506 - val_accuracy: 0.8686 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0047 - accuracy: 0.8725 - val_loss: 0.3381 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0048 - accuracy: 0.8634 - val_loss: 0.3366 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0046 - accuracy: 0.8643 - val_loss: 0.3362 - val_accuracy: 0.8718 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0048 - accuracy: 0.8579 - val_loss: 0.3353 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0045 - accuracy: 0.8689 - val_loss: 0.3318 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0045 - accuracy: 0.8652 - val_loss: 0.3281 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0044 - accuracy: 0.8789 - val_loss: 0.3253 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0044 - accuracy: 0.8807 - val_loss: 0.3219 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0043 - accuracy: 0.8761 - val_loss: 0.3209 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0043 - accuracy: 0.8761 - val_loss: 0.3169 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0041 - accuracy: 0.8852 - val_loss: 0.3106 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0042 - accuracy: 0.8761 - val_loss: 0.3057 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0041 - accuracy: 0.8871 - val_loss: 0.3032 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0041 - accuracy: 0.8807 - val_loss: 0.3013 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0037 - accuracy: 0.8925 - val_loss: 0.3037 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0039 - accuracy: 0.8998 - val_loss: 0.3041 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0039 - accuracy: 0.8925 - val_loss: 0.2935 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0038 - accuracy: 0.8971 - val_loss: 0.2938 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0038 - accuracy: 0.8962 - val_loss: 0.2913 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0039 - accuracy: 0.8925 - val_loss: 0.2921 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0038 - accuracy: 0.8971 - val_loss: 0.2918 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0040 - accuracy: 0.8834 - val_loss: 0.2831 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0037 - accuracy: 0.9016 - val_loss: 0.2801 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0037 - accuracy: 0.8980 - val_loss: 0.2788 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0037 - accuracy: 0.8907 - val_loss: 0.2805 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0037 - accuracy: 0.8925 - val_loss: 0.2797 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0036 - accuracy: 0.8953 - val_loss: 0.2713 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 59/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0036 - accuracy: 0.9053 - val_loss: 0.2796 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0035 - accuracy: 0.9044 - val_loss: 0.2795 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0035 - accuracy: 0.9089 - val_loss: 0.2700 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 62/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0036 - accuracy: 0.8989 - val_loss: 0.2695 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 63/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0035 - accuracy: 0.8925 - val_loss: 0.2765 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 64/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0034 - accuracy: 0.9026 - val_loss: 0.2732 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 65/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0033 - accuracy: 0.9208 - val_loss: 0.2708 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 66/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0033 - accuracy: 0.9135 - val_loss: 0.2629 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 67/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0035 - accuracy: 0.9007 - val_loss: 0.2623 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 68/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0032 - accuracy: 0.9153 - val_loss: 0.2630 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 69/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0032 - accuracy: 0.9089 - val_loss: 0.2585 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 70/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0033 - accuracy: 0.9080 - val_loss: 0.2579 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 71/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.9199 - val_loss: 0.2739 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 72/1000\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0032 - accuracy: 0.9089 - val_loss: 0.2699 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 73/1000\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 0.0029 - accuracy: 0.9217 - val_loss: 0.2531 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 74/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.9199 - val_loss: 0.2600 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 75/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0030 - accuracy: 0.9171 - val_loss: 0.2657 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 76/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0031 - accuracy: 0.9171 - val_loss: 0.2603 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 77/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0030 - accuracy: 0.9153 - val_loss: 0.2570 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 78/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0030 - accuracy: 0.9162 - val_loss: 0.2548 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 79/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0031 - accuracy: 0.9080 - val_loss: 0.2499 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 80/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0029 - accuracy: 0.9180 - val_loss: 0.2576 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 81/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0030 - accuracy: 0.9135 - val_loss: 0.2539 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 82/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0031 - accuracy: 0.9171 - val_loss: 0.2543 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 83/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0030 - accuracy: 0.9189 - val_loss: 0.2523 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 84/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0029 - accuracy: 0.9217 - val_loss: 0.2508 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 85/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0028 - accuracy: 0.9244 - val_loss: 0.2592 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 86/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0030 - accuracy: 0.9171 - val_loss: 0.2612 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 87/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0029 - accuracy: 0.9180 - val_loss: 0.2501 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 88/1000\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 0.0029 - accuracy: 0.9262 - val_loss: 0.2494 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 89/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0029 - accuracy: 0.9208 - val_loss: 0.2616 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 90/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0029 - accuracy: 0.9199 - val_loss: 0.2547 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 91/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0028 - accuracy: 0.9253 - val_loss: 0.2487 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 92/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0029 - accuracy: 0.9299 - val_loss: 0.2573 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 93/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0027 - accuracy: 0.9299 - val_loss: 0.2508 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 94/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0029 - accuracy: 0.9162 - val_loss: 0.2535 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 95/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0029 - accuracy: 0.9208 - val_loss: 0.2544 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 96/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0027 - accuracy: 0.9262 - val_loss: 0.2483 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 97/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0028 - accuracy: 0.9217 - val_loss: 0.2579 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 98/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0028 - accuracy: 0.9244 - val_loss: 0.2533 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 99/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0028 - accuracy: 0.9217 - val_loss: 0.2388 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 100/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0027 - accuracy: 0.9217 - val_loss: 0.2392 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 101/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0027 - accuracy: 0.9344 - val_loss: 0.2489 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 102/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0027 - accuracy: 0.9317 - val_loss: 0.2411 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 103/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0028 - accuracy: 0.9199 - val_loss: 0.2384 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 104/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0027 - accuracy: 0.9226 - val_loss: 0.2424 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 105/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0026 - accuracy: 0.9217 - val_loss: 0.2501 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 106/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 0.9353 - val_loss: 0.2518 - val_accuracy: 0.8718 - lr: 0.0010\n",
      "Epoch 107/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 0.9262 - val_loss: 0.2532 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 108/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0026 - accuracy: 0.9299 - val_loss: 0.2463 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 109/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0027 - accuracy: 0.9226 - val_loss: 0.2552 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 110/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0026 - accuracy: 0.9271 - val_loss: 0.2444 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 111/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0026 - accuracy: 0.9262 - val_loss: 0.2381 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 112/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0026 - accuracy: 0.9317 - val_loss: 0.2401 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 113/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0026 - accuracy: 0.9235 - val_loss: 0.2445 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 114/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0026 - accuracy: 0.9308 - val_loss: 0.2463 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 115/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0025 - accuracy: 0.9235 - val_loss: 0.2484 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 116/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0026 - accuracy: 0.9271 - val_loss: 0.2498 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 117/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0026 - accuracy: 0.9299 - val_loss: 0.2406 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 118/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0024 - accuracy: 0.9335 - val_loss: 0.2342 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 119/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0025 - accuracy: 0.9372 - val_loss: 0.2409 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 120/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0025 - accuracy: 0.9362 - val_loss: 0.2520 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 121/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 0.9381 - val_loss: 0.2489 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 122/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0025 - accuracy: 0.9235 - val_loss: 0.2412 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 123/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0024 - accuracy: 0.9326 - val_loss: 0.2355 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 124/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 0.9244 - val_loss: 0.2447 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 125/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0025 - accuracy: 0.9317 - val_loss: 0.2525 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 126/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0025 - accuracy: 0.9253 - val_loss: 0.2358 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 127/1000\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 0.0023 - accuracy: 0.9381 - val_loss: 0.2376 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 128/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0024 - accuracy: 0.9381 - val_loss: 0.2495 - val_accuracy: 0.8718 - lr: 0.0010\n",
      "Epoch 129/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0023 - accuracy: 0.9362 - val_loss: 0.2418 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 130/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0024 - accuracy: 0.9362 - val_loss: 0.2474 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 131/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0024 - accuracy: 0.9362 - val_loss: 0.2363 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 132/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0024 - accuracy: 0.9290 - val_loss: 0.2330 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 133/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0022 - accuracy: 0.9353 - val_loss: 0.2371 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 134/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0024 - accuracy: 0.9362 - val_loss: 0.2428 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 135/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0025 - accuracy: 0.9372 - val_loss: 0.2389 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 136/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0023 - accuracy: 0.9417 - val_loss: 0.2345 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 137/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0024 - accuracy: 0.9326 - val_loss: 0.2351 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 138/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0022 - accuracy: 0.9372 - val_loss: 0.2447 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 139/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0024 - accuracy: 0.9344 - val_loss: 0.2489 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 140/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0022 - accuracy: 0.9435 - val_loss: 0.2286 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 141/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0024 - accuracy: 0.9390 - val_loss: 0.2359 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 142/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0022 - accuracy: 0.9353 - val_loss: 0.2437 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 143/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0023 - accuracy: 0.9326 - val_loss: 0.2324 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 144/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0023 - accuracy: 0.9390 - val_loss: 0.2368 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 145/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0024 - accuracy: 0.9281 - val_loss: 0.2400 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 146/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0022 - accuracy: 0.9353 - val_loss: 0.2347 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 147/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0022 - accuracy: 0.9408 - val_loss: 0.2386 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 148/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0023 - accuracy: 0.9399 - val_loss: 0.2490 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 149/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0023 - accuracy: 0.9381 - val_loss: 0.2371 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 150/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0023 - accuracy: 0.9308 - val_loss: 0.2389 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 151/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0023 - accuracy: 0.9390 - val_loss: 0.2388 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 152/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 0.9444 - val_loss: 0.2414 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 153/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0021 - accuracy: 0.9408 - val_loss: 0.2431 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 154/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0024 - accuracy: 0.9399 - val_loss: 0.2422 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 155/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0022 - accuracy: 0.9399 - val_loss: 0.2459 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 156/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0021 - accuracy: 0.9454 - val_loss: 0.2496 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 157/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0022 - accuracy: 0.9444 - val_loss: 0.2410 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 158/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 0.9444 - val_loss: 0.2418 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 159/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0023 - accuracy: 0.9390 - val_loss: 0.2546 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 160/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 0.9490 - val_loss: 0.2391 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 161/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0023 - accuracy: 0.9353 - val_loss: 0.2491 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 162/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0022 - accuracy: 0.9390 - val_loss: 0.2387 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 163/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9490 - val_loss: 0.2311 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 164/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9508 - val_loss: 0.2511 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 165/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 0.9499 - val_loss: 0.2509 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 166/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0022 - accuracy: 0.9372 - val_loss: 0.2414 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 167/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 0.9435 - val_loss: 0.2389 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 168/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 0.9381 - val_loss: 0.2372 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 169/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 0.9390 - val_loss: 0.2407 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 170/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0022 - accuracy: 0.9435 - val_loss: 0.2314 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 171/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 0.9490 - val_loss: 0.2392 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 172/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 0.9463 - val_loss: 0.2395 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 173/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9499 - val_loss: 0.2443 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 174/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0022 - accuracy: 0.9372 - val_loss: 0.2571 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 175/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 0.9362 - val_loss: 0.2398 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 176/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9490 - val_loss: 0.2436 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 177/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9399 - val_loss: 0.2490 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 178/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0022 - accuracy: 0.9362 - val_loss: 0.2477 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 179/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9472 - val_loss: 0.2403 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 180/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9481 - val_loss: 0.2442 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 181/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 0.9435 - val_loss: 0.2462 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 182/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9444 - val_loss: 0.2430 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 183/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 0.9353 - val_loss: 0.2404 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 184/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 0.9426 - val_loss: 0.2479 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 185/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9454 - val_loss: 0.2539 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 186/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9417 - val_loss: 0.2435 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 187/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9435 - val_loss: 0.2515 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 188/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9517 - val_loss: 0.2471 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 189/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9472 - val_loss: 0.2479 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 190/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9499 - val_loss: 0.2463 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 191/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9572 - val_loss: 0.2450 - val_accuracy: 0.8910 - lr: 1.0000e-04\n",
      "Epoch 192/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9444 - val_loss: 0.2426 - val_accuracy: 0.8910 - lr: 1.0000e-04\n",
      "Epoch 193/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9517 - val_loss: 0.2413 - val_accuracy: 0.8974 - lr: 1.0000e-04\n",
      "Epoch 194/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9536 - val_loss: 0.2419 - val_accuracy: 0.8974 - lr: 1.0000e-04\n",
      "Epoch 195/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 0.9362 - val_loss: 0.2431 - val_accuracy: 0.8974 - lr: 1.0000e-04\n",
      "Epoch 196/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.9545 - val_loss: 0.2435 - val_accuracy: 0.8974 - lr: 1.0000e-04\n",
      "Epoch 197/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9508 - val_loss: 0.2432 - val_accuracy: 0.8974 - lr: 1.0000e-04\n",
      "Epoch 198/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 0.9472 - val_loss: 0.2428 - val_accuracy: 0.8974 - lr: 1.0000e-04\n",
      "Epoch 199/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9435 - val_loss: 0.2432 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 200/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.9536 - val_loss: 0.2419 - val_accuracy: 0.8974 - lr: 1.0000e-04\n",
      "Epoch 201/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9472 - val_loss: 0.2420 - val_accuracy: 0.8974 - lr: 1.0000e-04\n",
      "Epoch 202/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 0.9444 - val_loss: 0.2418 - val_accuracy: 0.8974 - lr: 1.0000e-04\n",
      "Epoch 203/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 0.9499 - val_loss: 0.2424 - val_accuracy: 0.8974 - lr: 1.0000e-04\n",
      "Epoch 204/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 0.9408 - val_loss: 0.2431 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 205/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.9472 - val_loss: 0.2437 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 206/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9426 - val_loss: 0.2438 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 207/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 0.9426 - val_loss: 0.2449 - val_accuracy: 0.8910 - lr: 1.0000e-04\n",
      "Epoch 208/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 0.9463 - val_loss: 0.2450 - val_accuracy: 0.8910 - lr: 1.0000e-04\n",
      "Epoch 209/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 0.9536 - val_loss: 0.2448 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 210/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9417 - val_loss: 0.2456 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 211/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9490 - val_loss: 0.2447 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 212/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9454 - val_loss: 0.2439 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 213/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9490 - val_loss: 0.2442 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 214/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 0.9435 - val_loss: 0.2441 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 215/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9472 - val_loss: 0.2442 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 216/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9490 - val_loss: 0.2436 - val_accuracy: 0.8974 - lr: 1.0000e-04\n",
      "Epoch 217/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9472 - val_loss: 0.2425 - val_accuracy: 0.8974 - lr: 1.0000e-04\n",
      "Epoch 218/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9472 - val_loss: 0.2429 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 219/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.9526 - val_loss: 0.2433 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 220/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9472 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 221/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9408 - val_loss: 0.2412 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 222/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.9536 - val_loss: 0.2421 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 223/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 0.9617 - val_loss: 0.2411 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 224/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.9517 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 225/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9499 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 226/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9399 - val_loss: 0.2426 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 227/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9499 - val_loss: 0.2440 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 228/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.9499 - val_loss: 0.2444 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 229/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9454 - val_loss: 0.2436 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 230/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0019 - accuracy: 0.9472 - val_loss: 0.2432 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 231/1000\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 0.0019 - accuracy: 0.9490 - val_loss: 0.2428 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 232/1000\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 0.0019 - accuracy: 0.9499 - val_loss: 0.2429 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 233/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0019 - accuracy: 0.9463 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 234/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 0.9517 - val_loss: 0.2409 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 235/1000\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 0.0020 - accuracy: 0.9454 - val_loss: 0.2422 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 236/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 0.9481 - val_loss: 0.2413 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 237/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.9563 - val_loss: 0.2416 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 238/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.9572 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 239/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9508 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 240/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 0.9563 - val_loss: 0.2419 - val_accuracy: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 241/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.9499 - val_loss: 0.2419 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 242/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.9499 - val_loss: 0.2421 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 243/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9481 - val_loss: 0.2421 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 244/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0021 - accuracy: 0.9417 - val_loss: 0.2421 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 245/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9490 - val_loss: 0.2423 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 246/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 0.9472 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 247/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9444 - val_loss: 0.2425 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 248/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9444 - val_loss: 0.2425 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 249/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9490 - val_loss: 0.2425 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 250/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9499 - val_loss: 0.2425 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 251/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9417 - val_loss: 0.2426 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 252/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 0.9417 - val_loss: 0.2427 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 253/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 0.9472 - val_loss: 0.2426 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 254/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 0.9454 - val_loss: 0.2426 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 255/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9536 - val_loss: 0.2428 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 256/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9536 - val_loss: 0.2429 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 257/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 0.9417 - val_loss: 0.2428 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 258/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9481 - val_loss: 0.2427 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 259/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9463 - val_loss: 0.2426 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 260/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 0.9517 - val_loss: 0.2426 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 261/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 0.9490 - val_loss: 0.2426 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 262/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.9526 - val_loss: 0.2427 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 263/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.9545 - val_loss: 0.2428 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 264/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9481 - val_loss: 0.2428 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 265/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 0.9545 - val_loss: 0.2427 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 266/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9499 - val_loss: 0.2428 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 267/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9472 - val_loss: 0.2429 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 268/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 0.9426 - val_loss: 0.2428 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 269/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 0.9490 - val_loss: 0.2428 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 270/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 0.9435 - val_loss: 0.2427 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 271/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.9526 - val_loss: 0.2427 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 272/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9526 - val_loss: 0.2428 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 273/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 0.9517 - val_loss: 0.2429 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 274/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 0.9490 - val_loss: 0.2428 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 275/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 0.9499 - val_loss: 0.2428 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 276/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.9481 - val_loss: 0.2428 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 277/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9435 - val_loss: 0.2426 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 278/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.9508 - val_loss: 0.2426 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 279/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.9545 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 280/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9508 - val_loss: 0.2423 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 281/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.9517 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 282/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 0.9435 - val_loss: 0.2423 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 283/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9508 - val_loss: 0.2422 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 284/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 0.9444 - val_loss: 0.2421 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 285/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0017 - accuracy: 0.9517 - val_loss: 0.2422 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 286/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 0.9417 - val_loss: 0.2423 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 287/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.9508 - val_loss: 0.2423 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 288/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 0.9536 - val_loss: 0.2422 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 289/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.9454 - val_loss: 0.2423 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 290/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9472 - val_loss: 0.2423 - val_accuracy: 0.8942 - lr: 1.0000e-05\n",
      "Epoch 291/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9517 - val_loss: 0.2423 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 292/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9472 - val_loss: 0.2423 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 293/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 0.9444 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 294/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.9545 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 295/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9508 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 296/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9517 - val_loss: 0.2423 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 297/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9472 - val_loss: 0.2423 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 298/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 0.9463 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 299/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.9526 - val_loss: 0.2423 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 300/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 0.9581 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 301/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 0.9517 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 302/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.9526 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 303/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 0.9463 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 304/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9481 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 305/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9490 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 306/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 0.9463 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 307/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.9545 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 308/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 0.9463 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 309/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 0.9481 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 310/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 0.9554 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 311/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 0.9517 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 312/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9472 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 313/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9563 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 314/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9426 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 315/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 0.9545 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 316/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.9499 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 317/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.9526 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 318/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.9554 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 319/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0017 - accuracy: 0.9608 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 320/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 0.9472 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 321/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 0.9454 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 322/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.9536 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 323/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 0.9472 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 324/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 0.9508 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 325/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.9481 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 326/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.9563 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 327/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9426 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 328/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 0.9454 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 329/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 0.9545 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 330/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.9463 - val_loss: 0.2424 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 331/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 0.9536 - val_loss: 0.2425 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 332/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 0.9435 - val_loss: 0.2425 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 333/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9435 - val_loss: 0.2425 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 334/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9490 - val_loss: 0.2425 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 335/1000\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 0.9472 - val_loss: 0.2425 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 336/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9563 - val_loss: 0.2425 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 337/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0019 - accuracy: 0.9463 - val_loss: 0.2425 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 338/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0018 - accuracy: 0.9536 - val_loss: 0.2425 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 339/1000\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.9526 - val_loss: 0.2425 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Epoch 340/1000\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.9526 - val_loss: 0.2425 - val_accuracy: 0.8942 - lr: 1.0000e-06\n",
      "Training time: 41.64031720161438 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Train the model\n",
    "def train_network(model, train_x, train_y, test_x, test_y):\n",
    "    verbose = 1 # 0 for no logging to stdout, 1 for progress bar logging, 2 for one log line per epoch.\n",
    "    epochs = 1000\n",
    "    batch_size = 128\n",
    "    model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, validation_data=(test_x, test_y), class_weight = class_weights, callbacks = [model_checkpoint_callback, reduce_lr, early_stopping], verbose=verbose)\n",
    "    _, accuracy = model.evaluate(test_x, test_y, batch_size=batch_size, verbose=0)\n",
    "    return model\n",
    "\n",
    "start_time = time.time()\n",
    "model = train_network(model, train_x, train_y, test_x, test_y)\n",
    "print(\"Training time: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of filtered prediction: 0.75\n",
      "Highest false confidence: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "highest_false_confidence = 0\n",
    "\n",
    "# model.load_weights(checkpoint_filepath)\n",
    "y_prediction = model.predict(test_x)\n",
    "\n",
    "threshold = 0.9\n",
    "# remove all the prediction with probability less than threshold\n",
    "filtered_pred = []\n",
    "filtered_test = []\n",
    "for i in range(len(y_prediction)):\n",
    "    if np.max(y_prediction[i]) > threshold:\n",
    "        filtered_pred.append(np.argmax(y_prediction[i]))\n",
    "        filtered_test.append(np.argmax(test_y[i]))\n",
    "        if np.max(y_prediction[i]) > highest_false_confidence and np.argmax(y_prediction[i]) != np.argmax(test_y[i]):\n",
    "            highest_false_confidence = np.max(y_prediction[i])\n",
    "\n",
    "# print proportion of filtered prediction\n",
    "print(\"Proportion of filtered prediction: \" + str(len(filtered_pred)/len(y_prediction)))\n",
    "\n",
    "# print highest false confidence\n",
    "print(\"Highest false confidence: \" + str(highest_false_confidence))\n",
    "\n",
    "result = confusion_matrix(filtered_test, filtered_pred)\n",
    "\n",
    "# result = confusion_matrix(np.argmax(test_y, axis=1), y_prediction)\n",
    "sns.heatmap(result, annot=True, fmt=\"d\", xticklabels=action_types, yticklabels=action_types)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# print accuracy\n",
    "print(\"Accuracy: \" + str(np.sum(np.diag(result))/np.sum(result)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best prob: 0.96064967\n",
      "best prob: 0.97462136\n",
      "best prob: 0.9609415\n",
      "best prob: 0.90571105\n",
      "best prob: 0.91638255\n",
      "best prob: 0.90776634\n",
      "best prob: 0.95757806\n",
      "best prob: 0.9129159\n",
      "best prob: 0.84548783\n",
      "best prob: 0.9567201\n",
      "best prob: 0.93899465\n",
      "best prob: 0.9792796\n",
      "best prob: 0.9807546\n",
      "best prob: 0.93193555\n",
      "best prob: 0.94348216\n",
      "best prob: 0.86629355\n",
      "best prob: 0.9417254\n",
      "best prob: 0.91368335\n",
      "best prob: 0.9829715\n",
      "best prob: 0.92211264\n",
      "best prob: 0.9444642\n",
      "best prob: 0.8866343\n",
      "best prob: 0.92842185\n",
      "best prob: 0.93360114\n",
      "best prob: 0.9116266\n",
      "best prob: 0.9195915\n",
      "best prob: 0.93041545\n",
      "best prob: 0.95355713\n",
      "best prob: 0.9051587\n",
      "best prob: 0.94141954\n",
      "best prob: 0.92457545\n",
      "best prob: 0.94886756\n",
      "best prob: 0.923784\n",
      "best prob: 0.9850567\n",
      "best prob: 0.98419094\n",
      "best prob: 0.8509441\n",
      "best prob: 0.9053678\n",
      "best prob: 0.94724625\n",
      "best prob: 0.97090924\n",
      "best prob: 0.9299642\n",
      "best prob: 0.91607124\n",
      "best prob: 0.9046542\n",
      "best prob: 0.9266557\n",
      "best prob: 0.9505747\n",
      "best prob: 0.8603502\n",
      "best prob: 0.900302\n",
      "best prob: 0.9571177\n",
      "best prob: 0.9290587\n",
      "best prob: 0.90337855\n",
      "best prob: 0.88244385\n",
      "best prob: 0.9014661\n",
      "best prob: 0.9495978\n",
      "best prob: 0.9563703\n",
      "best prob: 0.90911555\n",
      "best prob: 0.96964663\n",
      "best prob: 0.9294243\n",
      "best prob: 0.9335831\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7017543859649122\n",
      "Highest false confidence: 0.97462136\n"
     ]
    }
   ],
   "source": [
    "# evaluate actual performance\n",
    "pred = []\n",
    "actual = []\n",
    "highest_false_confidence = 0\n",
    "threshold = 0.9\n",
    "for i in range(len(test_x_eval)):\n",
    "    data = np.array(test_x_eval[i])\n",
    "    # sliding window until the prediction has probability greater than threshold, or end of the sequence and give the prediction with highest probability\n",
    "    best_pred, best_prob = 0, 0\n",
    "    for w in range(conv1stride, len(data), conv1stride):\n",
    "        x = np.array(data[max(0, w-conv1kernel):w])\n",
    "        x = np.concatenate((x, np.zeros((window_size - x.shape[0], 6))))\n",
    "        x = np.float32(x)/4096\n",
    "        y = model.predict(np.array([x]))\n",
    "        if np.max(y) > highest_false_confidence and np.argmax(y) != np.argmax(test_y_eval[i]):\n",
    "            highest_false_confidence = np.max(y)\n",
    "        if np.max(y) > best_prob:\n",
    "            best_pred = np.argmax(y)\n",
    "            best_prob = np.max(y)\n",
    "        if np.max(y) > threshold:\n",
    "            break\n",
    "    print(\"best prob: \" + str(best_prob))\n",
    "    pred.append(best_pred)\n",
    "    actual.append(np.argmax(test_y_eval[i]))\n",
    "result = confusion_matrix(actual, pred)\n",
    "sns.heatmap(result, annot=True, fmt=\"d\", xticklabels=action_types, yticklabels=action_types)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# print accuracy\n",
    "print(\"Accuracy: \" + str(np.sum(np.diag(result))/np.sum(result)))\n",
    "\n",
    "# print highest false confidence\n",
    "print(\"Highest false confidence: \" + str(highest_false_confidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"window shape: {window_size, data_depth}\")\n",
    "print(f\"kernel shape: {conv1kernel, data_depth}\")\n",
    "print(f\"first layer weights shape: {model.layers[0].get_weights()[0].shape}\")\n",
    "print(f\"first layer output shape: {model.layers[0].output_shape}\")\n",
    "print(f\"second layer weights shape: {model.layers[3].get_weights()[0].shape}\")\n",
    "print(f\"second layer output shape: {model.layers[3].output_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out weights and biases one by one\n",
    "layers_indexes = [0, 3]\n",
    "\n",
    "for layer_index in layers_indexes:\n",
    "    layer = model.layers[layer_index]\n",
    "    layer_name = layer.name\n",
    "    weights = layer.get_weights()\n",
    "    print(weights[0].shape)\n",
    "    print(f\"INPUT_DTYPE model_param_{layer_name}_weights\")\n",
    "    for i in range(weights[0].shape[-1]):\n",
    "        print(\"index\", i)\n",
    "        print(np.transpose(np.transpose(weights[0])[i]))\n",
    "    print(f\"INPUT_DTYPE model_param_{layer_name}_biases\")\n",
    "    print(weights[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directly print out weights and biases\n",
    "layers_indexes = [0, 3]\n",
    "\n",
    "for layer_index in layers_indexes:\n",
    "    layer = model.layers[layer_index]\n",
    "    layer_name = layer.name\n",
    "    weights = layer.get_weights()\n",
    "    if layer_index == 0:\n",
    "        layer_name = \"CNN\"\n",
    "        weights_size_definition = \"[CNN_KERNEL_LENGTH][CNN_KERNEL_DEPTH][CNN_KERNEL_COUNT]\"\n",
    "        bias_size_definition = \"[CNN_KERNEL_COUNT]\"\n",
    "    else:\n",
    "        layer_name = \"dense\"\n",
    "        weights_size_definition = \"[DENSE_INPUT_NODES][DENSE_OUTPUT_NODES]\"\n",
    "        bias_size_definition = \"[DENSE_OUTPUT_NODES]\"\n",
    "    print(f\"static INPUT_DTYPE {layer_name}_weights{weights_size_definition} = {{\" + \", \".join([str(x) for x in weights[0].reshape(-1)]) + \"};\")\n",
    "    print(f\"static INPUT_DTYPE {layer_name}_bias{bias_size_definition} = {{\" + \", \".join([str(x) for x in weights[1]]) + \"};\")\n",
    "\n",
    "    # save weights and biases to file\n",
    "    np.save(f\"{layer_name}_weights.npy\", weights[0])\n",
    "    np.save(f\"{layer_name}_bias.npy\", weights[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directly print out test dataset\n",
    "n_values_per_line = 10\n",
    "dataset_size = len(test_x)\n",
    "# dataset_size = 1\n",
    "dataset_start_index = 0\n",
    "print(\"#define DATASET_SIZE\", dataset_size)\n",
    "\n",
    "# print out float test dataset\n",
    "print(f\"const float test_x[DATASET_SIZE][INPUT_LENGTH][INPUT_DEPTH] = {{\")\n",
    "for text_x_index in range(dataset_start_index, min(test_x.shape[0], dataset_start_index + dataset_size)):\n",
    "    for datapoint_index in range(0, len(test_x[text_x_index])):\n",
    "        for i in range(0, len(test_x[text_x_index][datapoint_index]), n_values_per_line):\n",
    "            print(\", \".join([str(x) for x in test_x_copy[text_x_index][datapoint_index][i:i+n_values_per_line]]) + \",\")\n",
    "print(\"};\") \n",
    "    \n",
    "print(f\"const int test_y[DATASET_SIZE][DENSE_OUTPUT_NODES] = {{\")\n",
    "for text_x_index in range(dataset_start_index, min(test_x.shape[0], dataset_start_index + dataset_size)):\n",
    "    for i in range(0, len(test_y[text_x_index]), n_values_per_line):\n",
    "        print(\", \".join([str(int(x)) for x in test_y[text_x_index][i:i+n_values_per_line]]) + \",\")\n",
    "print(\"};\")\n",
    "\n",
    "# save the test dataset\n",
    "np.save(\"test_x.npy\", test_x_copy)\n",
    "np.save(\"test_y.npy\", test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print model output without the last layer\n",
    "from keras.models import Model\n",
    "model_without_last_layer = Model(inputs=model.input, outputs=model.layers[-2].output)\n",
    "model_without_last_layer.summary()\n",
    "predicted_result = model_without_last_layer.predict(test_x)[0]\n",
    "print(predicted_result.shape)\n",
    "print(predicted_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('capstone')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f82d4ec2f4e1a7949fc551b5039d8b80c5fc6c2b366144cfac1fa6211cdc80ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
