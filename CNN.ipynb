{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, Conv1D, MaxPooling1D, Softmax, Reshape\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.backend import clear_session\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process dataset\n",
    "Extract data from the txt file for each user. We only extract the data for the time frame where the user is doing one action, not across different actions. Then we segment the data into 2 seconds window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file loader\n",
    "from os.path import isfile\n",
    "\n",
    "def load_data(file):\n",
    "    data = pd.read_csv(file, header=None)\n",
    "    return data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from Dataset/user0\n",
      "Loaded 15 shield files\n",
      "Loaded 15 reload files\n",
      "Loaded 15 grenade files\n",
      "Loaded 20 final files\n",
      "Loading data from Dataset/user1\n",
      "Loaded 20 shield files\n",
      "Loaded 15 reload files\n",
      "Loaded 20 grenade files\n",
      "Loaded 20 final files\n",
      "Loading data from Dataset/user2\n",
      "Loaded 20 shield files\n",
      "Loaded 13 reload files\n",
      "Loaded 14 grenade files\n",
      "Loaded 20 final files\n",
      "Loading data from Dataset/user3\n",
      "Loaded 20 shield files\n",
      "Loaded 14 reload files\n",
      "Loaded 20 grenade files\n",
      "Loaded 20 final files\n",
      "Dataset initialized with size: 281\n",
      "Class 0 has 75 samples\n",
      "Class 1 has 57 samples\n",
      "Class 2 has 69 samples\n",
      "Class 3 has 80 samples\n",
      "Loading idle data from Dataset/user0\n",
      "Loading idle data from Dataset/user1\n",
      "Loading idle data from Dataset/user2\n",
      "Loading idle data from Dataset/user3\n",
      "Idle dataset initialized with size: 20\n",
      "Dataset size after sliding window: 1703\n",
      "Class 0 has 853 samples\n",
      "Class 1 has 230 samples\n",
      "Class 2 has 286 samples\n",
      "Class 3 has 334 samples\n",
      "\n",
      "Test set distribution\n",
      "Class 0 has 75 samples\n",
      "Class 1 has 72 samples\n",
      "Class 2 has 59 samples\n",
      "Class 3 has 106 samples\n"
     ]
    }
   ],
   "source": [
    "window_size = 75   # 50Hz, 75 samples = 1.5s of movement\n",
    "window_stride = 25\n",
    "action_types = ('shield', 'reload', 'grenade', 'final')\n",
    "data_depth = 6\n",
    "\n",
    "dataset_users = [0, 1, 2, 3]\n",
    "\n",
    "# Function to load dataset\n",
    "def load_dataset(data_dir):\n",
    "    dataset_x = []\n",
    "    dataset_y = []\n",
    "    \n",
    "    for i in dataset_users:\n",
    "        user_data_dir = f\"{data_dir}/user{i}\"\n",
    "        print(f\"Loading data from {user_data_dir}\")\n",
    "    \n",
    "        for action_type in action_types:\n",
    "\n",
    "            for i in range(1, 100, 1):\n",
    "                # if file exists\n",
    "                if not isfile(user_data_dir + f\"/{action_type}{i}.csv\"):\n",
    "                    # print number of files loaded\n",
    "                    print(f\"Loaded {i-1} {action_type} files\")\n",
    "                    break\n",
    "                data = load_data(user_data_dir + f\"/{action_type}{i}.csv\")\n",
    "                dataset_x.append(np.int32(data))\n",
    "                dataset_y.append(action_types.index(action_type))\n",
    "\n",
    "    print(\"Dataset initialized with size: \" + str(len(dataset_y)))\n",
    "    for i in range(len(action_types)):\n",
    "        print(\"Class \" + str(i) + \" has \" + str(dataset_y.count(i)) + \" samples\")\n",
    "    dataset_y = to_categorical(dataset_y)\n",
    "    return dataset_x, np.array(dataset_y)\n",
    "\n",
    "def load_idle_dataset(data_dir):\n",
    "    dataset_x = []\n",
    "    dataset_y = []\n",
    "    \n",
    "    for i in dataset_users:\n",
    "        user_data_dir = f\"{data_dir}/user{i}\"\n",
    "        print(f\"Loading idle data from {user_data_dir}\")\n",
    "    \n",
    "        for i in range(1, 100, 1):\n",
    "            # if file exists\n",
    "            if not isfile(user_data_dir + f\"/idle{i}.csv\"):\n",
    "                break\n",
    "            data = load_data(user_data_dir + f\"/idle{i}.csv\")\n",
    "            dataset_x.append(data)\n",
    "            dataset_y.append([0.25, 0.25, 0.25, 0.25])\n",
    "\n",
    "    print(\"Idle dataset initialized with size: \" + str(len(dataset_y)))\n",
    "    return dataset_x, np.array(dataset_y)\n",
    "\n",
    "# To do sliding window on the data\n",
    "def sliding_window(data_X, data_Y, window_size, window_stride):\n",
    "    dataset_X_w_sliding = []\n",
    "    dataset_Y_w_sliding = []\n",
    "    for i in range(len(data_X)):\n",
    "        for j in range(0, len(data_X[i]) - window_size+1, window_stride):\n",
    "            dataset_X_w_sliding.append(data_X[i][j:j + window_size])\n",
    "            dataset_Y_w_sliding.append(data_Y[i])\n",
    "    return np.array(dataset_X_w_sliding), np.array(dataset_Y_w_sliding)\n",
    "\n",
    "\n",
    "# load dataset\n",
    "dataset_x, dataset_y = load_dataset(\"Dataset\")\n",
    "\n",
    "# split into train and test sets\n",
    "train_x, test_x, train_y, test_y = train_test_split(dataset_x, dataset_y, test_size=0.2, stratify = dataset_y, random_state=666)\n",
    "\n",
    "# backup test set for evaluation\n",
    "test_x_eval = copy.deepcopy(test_x)\n",
    "test_y_eval = copy.deepcopy(test_y)\n",
    "\n",
    "# combine the training data with idle data\n",
    "dataset_x_idle, dataset_y_idle = load_idle_dataset(\"Dataset\")\n",
    "train_x.extend(dataset_x_idle)\n",
    "train_y = np.concatenate((train_y, dataset_y_idle), axis=0)\n",
    "\n",
    "# sliding window after train_test_split\n",
    "train_x, train_y = sliding_window(train_x, train_y, window_size, window_stride)\n",
    "test_x, test_y = sliding_window(test_x, test_y, window_size, window_stride)\n",
    "\n",
    "# print dataset size after sliding window\n",
    "print(\"Dataset size after sliding window: \" + str(len(train_y)))\n",
    "\n",
    "# calculate class weights\n",
    "class_weights = {}\n",
    "for i in range(len(action_types)):\n",
    "    class_weights[i] = 1 / dataset_y[:, i].sum()\n",
    "\n",
    "# print dataset disribution\n",
    "train_y_temp = np.argmax(train_y, axis=1)\n",
    "for i in range(len(action_types)):\n",
    "    print(\"Class \" + str(i) + \" has \" + str(train_y_temp.tolist().count(i)) + \" samples\")\n",
    "\n",
    "# backup test_x for c_sim and cosim\n",
    "test_x_copy = copy.deepcopy(test_x)\n",
    "\n",
    "# convert data from int16 to float32\n",
    "train_x, test_x = np.float32(train_x)/4096, np.float32(test_x)/4096\n",
    "# print(\"sample test x data: \" + str(test_x[0]))\n",
    "\n",
    "# summary of test dataset\n",
    "test = np.argmax(test_y, axis=1)\n",
    "print(\"\\nTest set distribution\")\n",
    "for i in range(len(action_types)):\n",
    "    print(\"Class \" + str(i) + \" has \" + str(test.tolist().count(i)) + \" samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 73, 32)            608       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 73, 32)            0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 24, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 22, 16)            1552      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 22, 16)            0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 7, 16)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 112)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 452       \n",
      "                                                                 \n",
      " softmax (Softmax)           (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,612\n",
      "Trainable params: 2,612\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 12:11:19.971648: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conv1filters = 32\n",
    "conv1kernel = 3\n",
    "conv1stride = 1\n",
    "\n",
    "clear_session()\n",
    "model = Sequential()\n",
    "model.add(Conv1D(conv1filters, conv1kernel, strides=conv1stride, activation='relu', input_shape=(window_size, 6)))\n",
    "model.add(Dropout(0.5)) # 50% dropout\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Conv1D(16, 3, activation='relu'))\n",
    "model.add(Dropout(0.5)) # 50% dropout\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(len(action_types)))\n",
    "model.add(Softmax())\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# performance before training\n",
    "y_prediction = np.argmax(model.predict(test_x), axis=1)\n",
    "result = confusion_matrix(np.argmax(test_y, axis=1), y_prediction)\n",
    "sns.heatmap(result, annot=True, fmt=\"d\", xticklabels=action_types, yticklabels=action_types)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint callback\n",
    "checkpoint_filepath = \"model_checkpoint/\"\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "# learning rate reduce on plateau callback\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=50, min_lr=0)\n",
    "\n",
    "# early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=200, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 12:11:29.506937: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 26ms/step - loss: 0.0232 - accuracy: 0.3194 - val_loss: 1.3234 - val_accuracy: 0.3590 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      " 6/14 [===========>..................] - ETA: 0s - loss: 0.0202 - accuracy: 0.3216"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 12:11:30.078703: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0195 - accuracy: 0.3171 - val_loss: 1.2935 - val_accuracy: 0.4327 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0179 - accuracy: 0.3564 - val_loss: 1.2630 - val_accuracy: 0.5064 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0173 - accuracy: 0.3705 - val_loss: 1.2147 - val_accuracy: 0.5801 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0164 - accuracy: 0.4046 - val_loss: 1.1538 - val_accuracy: 0.6635 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0155 - accuracy: 0.4281 - val_loss: 1.0867 - val_accuracy: 0.6923 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 0.0147 - accuracy: 0.4756 - val_loss: 1.0175 - val_accuracy: 0.7179 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0142 - accuracy: 0.4997 - val_loss: 0.9705 - val_accuracy: 0.7596 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 0.0136 - accuracy: 0.5437 - val_loss: 0.9322 - val_accuracy: 0.7821 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0131 - accuracy: 0.5531 - val_loss: 0.8948 - val_accuracy: 0.7949 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0129 - accuracy: 0.5555 - val_loss: 0.8697 - val_accuracy: 0.8045 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0123 - accuracy: 0.5942 - val_loss: 0.8320 - val_accuracy: 0.8077 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0122 - accuracy: 0.5931 - val_loss: 0.8066 - val_accuracy: 0.8269 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0119 - accuracy: 0.5866 - val_loss: 0.7909 - val_accuracy: 0.8333 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0118 - accuracy: 0.6066 - val_loss: 0.7748 - val_accuracy: 0.8333 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0116 - accuracy: 0.6119 - val_loss: 0.7606 - val_accuracy: 0.8301 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0114 - accuracy: 0.6072 - val_loss: 0.7525 - val_accuracy: 0.8397 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0115 - accuracy: 0.5948 - val_loss: 0.7345 - val_accuracy: 0.8590 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0113 - accuracy: 0.6148 - val_loss: 0.7155 - val_accuracy: 0.8526 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0112 - accuracy: 0.6312 - val_loss: 0.7138 - val_accuracy: 0.8622 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0110 - accuracy: 0.6160 - val_loss: 0.7125 - val_accuracy: 0.8558 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0109 - accuracy: 0.6289 - val_loss: 0.6990 - val_accuracy: 0.8558 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0109 - accuracy: 0.6054 - val_loss: 0.6881 - val_accuracy: 0.8590 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0108 - accuracy: 0.5984 - val_loss: 0.6817 - val_accuracy: 0.8590 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0108 - accuracy: 0.5995 - val_loss: 0.6711 - val_accuracy: 0.8494 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0107 - accuracy: 0.5972 - val_loss: 0.6687 - val_accuracy: 0.8622 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0106 - accuracy: 0.6089 - val_loss: 0.6596 - val_accuracy: 0.8622 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0106 - accuracy: 0.6142 - val_loss: 0.6510 - val_accuracy: 0.8558 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0105 - accuracy: 0.6025 - val_loss: 0.6410 - val_accuracy: 0.8622 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0106 - accuracy: 0.5925 - val_loss: 0.6459 - val_accuracy: 0.8622 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0106 - accuracy: 0.5948 - val_loss: 0.6456 - val_accuracy: 0.8590 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0104 - accuracy: 0.5942 - val_loss: 0.6318 - val_accuracy: 0.8654 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0104 - accuracy: 0.5984 - val_loss: 0.6254 - val_accuracy: 0.8718 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0104 - accuracy: 0.5937 - val_loss: 0.6274 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0103 - accuracy: 0.6048 - val_loss: 0.6215 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0103 - accuracy: 0.5995 - val_loss: 0.6240 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0103 - accuracy: 0.5895 - val_loss: 0.6203 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0102 - accuracy: 0.5966 - val_loss: 0.6176 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0102 - accuracy: 0.5948 - val_loss: 0.6021 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0101 - accuracy: 0.5931 - val_loss: 0.5978 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0102 - accuracy: 0.5937 - val_loss: 0.5982 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0101 - accuracy: 0.5948 - val_loss: 0.5953 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0101 - accuracy: 0.5907 - val_loss: 0.5971 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0100 - accuracy: 0.5960 - val_loss: 0.5939 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0101 - accuracy: 0.5989 - val_loss: 0.5881 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0100 - accuracy: 0.5960 - val_loss: 0.5888 - val_accuracy: 0.8718 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0100 - accuracy: 0.5907 - val_loss: 0.5781 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0100 - accuracy: 0.6019 - val_loss: 0.5720 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0100 - accuracy: 0.5972 - val_loss: 0.5731 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0099 - accuracy: 0.6078 - val_loss: 0.5710 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0099 - accuracy: 0.5966 - val_loss: 0.5796 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0099 - accuracy: 0.6042 - val_loss: 0.5719 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0099 - accuracy: 0.6013 - val_loss: 0.5709 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0099 - accuracy: 0.6160 - val_loss: 0.5692 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0099 - accuracy: 0.6066 - val_loss: 0.5619 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0098 - accuracy: 0.6025 - val_loss: 0.5598 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0097 - accuracy: 0.6189 - val_loss: 0.5614 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0097 - accuracy: 0.6160 - val_loss: 0.5618 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 59/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0098 - accuracy: 0.6218 - val_loss: 0.5499 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0099 - accuracy: 0.6154 - val_loss: 0.5601 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0098 - accuracy: 0.6130 - val_loss: 0.5538 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 62/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0097 - accuracy: 0.6036 - val_loss: 0.5638 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 63/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0097 - accuracy: 0.6277 - val_loss: 0.5591 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 64/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0097 - accuracy: 0.6218 - val_loss: 0.5488 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 65/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0097 - accuracy: 0.6078 - val_loss: 0.5534 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 66/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0096 - accuracy: 0.6213 - val_loss: 0.5398 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 67/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0096 - accuracy: 0.6224 - val_loss: 0.5367 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 68/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0096 - accuracy: 0.6248 - val_loss: 0.5367 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 69/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0097 - accuracy: 0.6277 - val_loss: 0.5455 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 70/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0097 - accuracy: 0.6242 - val_loss: 0.5416 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 71/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0096 - accuracy: 0.6224 - val_loss: 0.5359 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 72/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0096 - accuracy: 0.6289 - val_loss: 0.5325 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 73/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0097 - accuracy: 0.6107 - val_loss: 0.5293 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 74/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0096 - accuracy: 0.6459 - val_loss: 0.5341 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 75/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0096 - accuracy: 0.6130 - val_loss: 0.5345 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 76/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0096 - accuracy: 0.6271 - val_loss: 0.5328 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 77/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0096 - accuracy: 0.6218 - val_loss: 0.5310 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 78/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0095 - accuracy: 0.6359 - val_loss: 0.5256 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 79/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0095 - accuracy: 0.6412 - val_loss: 0.5186 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 80/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0095 - accuracy: 0.6254 - val_loss: 0.5238 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 81/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0095 - accuracy: 0.6342 - val_loss: 0.5176 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 82/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0096 - accuracy: 0.6389 - val_loss: 0.5183 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 83/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0095 - accuracy: 0.6324 - val_loss: 0.5167 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 84/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0094 - accuracy: 0.6353 - val_loss: 0.5208 - val_accuracy: 0.8686 - lr: 0.0010\n",
      "Epoch 85/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0095 - accuracy: 0.6400 - val_loss: 0.5082 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 86/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0094 - accuracy: 0.6389 - val_loss: 0.5149 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 87/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0095 - accuracy: 0.6418 - val_loss: 0.5028 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 88/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0094 - accuracy: 0.6207 - val_loss: 0.5041 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 89/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0094 - accuracy: 0.6400 - val_loss: 0.5023 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 90/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0094 - accuracy: 0.6312 - val_loss: 0.5086 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 91/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0094 - accuracy: 0.6365 - val_loss: 0.5068 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 92/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0094 - accuracy: 0.6447 - val_loss: 0.5019 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 93/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0094 - accuracy: 0.6166 - val_loss: 0.5052 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 94/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0094 - accuracy: 0.6524 - val_loss: 0.5022 - val_accuracy: 0.9071 - lr: 0.0010\n",
      "Epoch 95/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0095 - accuracy: 0.6447 - val_loss: 0.4990 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 96/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0094 - accuracy: 0.6148 - val_loss: 0.5061 - val_accuracy: 0.8718 - lr: 0.0010\n",
      "Epoch 97/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0094 - accuracy: 0.6389 - val_loss: 0.4977 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 98/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0093 - accuracy: 0.6406 - val_loss: 0.5002 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 99/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0094 - accuracy: 0.6524 - val_loss: 0.4931 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 100/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0094 - accuracy: 0.6359 - val_loss: 0.4914 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 101/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0093 - accuracy: 0.6447 - val_loss: 0.4918 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 102/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0093 - accuracy: 0.6307 - val_loss: 0.4922 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 103/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0093 - accuracy: 0.6348 - val_loss: 0.4962 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 104/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0093 - accuracy: 0.6530 - val_loss: 0.4926 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 105/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0093 - accuracy: 0.6342 - val_loss: 0.4865 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 106/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0093 - accuracy: 0.6453 - val_loss: 0.4872 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 107/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0093 - accuracy: 0.6301 - val_loss: 0.4942 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 108/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0092 - accuracy: 0.6524 - val_loss: 0.4901 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 109/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0092 - accuracy: 0.6424 - val_loss: 0.4841 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 110/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0093 - accuracy: 0.6459 - val_loss: 0.4912 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 111/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0093 - accuracy: 0.6260 - val_loss: 0.4866 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 112/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0093 - accuracy: 0.6353 - val_loss: 0.4845 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 113/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0092 - accuracy: 0.6371 - val_loss: 0.4873 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 114/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0093 - accuracy: 0.6471 - val_loss: 0.4881 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 115/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0092 - accuracy: 0.6447 - val_loss: 0.4906 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 116/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0093 - accuracy: 0.6436 - val_loss: 0.4847 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 117/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0092 - accuracy: 0.6442 - val_loss: 0.4743 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 118/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0091 - accuracy: 0.6577 - val_loss: 0.4681 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 119/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0092 - accuracy: 0.6318 - val_loss: 0.4746 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 120/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0092 - accuracy: 0.6377 - val_loss: 0.4759 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 121/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0092 - accuracy: 0.6424 - val_loss: 0.4792 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 122/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0093 - accuracy: 0.6524 - val_loss: 0.4852 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 123/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0091 - accuracy: 0.6541 - val_loss: 0.4759 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 124/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0092 - accuracy: 0.6494 - val_loss: 0.4730 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 125/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0092 - accuracy: 0.6377 - val_loss: 0.4621 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 126/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0093 - accuracy: 0.6301 - val_loss: 0.4729 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 127/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0091 - accuracy: 0.6418 - val_loss: 0.4714 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 128/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0092 - accuracy: 0.6459 - val_loss: 0.4691 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 129/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0092 - accuracy: 0.6618 - val_loss: 0.4684 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 130/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0092 - accuracy: 0.6694 - val_loss: 0.4694 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 131/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0092 - accuracy: 0.6442 - val_loss: 0.4718 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 132/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0091 - accuracy: 0.6453 - val_loss: 0.4633 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 133/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0092 - accuracy: 0.6436 - val_loss: 0.4591 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 134/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0091 - accuracy: 0.6659 - val_loss: 0.4700 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 135/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0091 - accuracy: 0.6577 - val_loss: 0.4574 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 136/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0091 - accuracy: 0.6553 - val_loss: 0.4525 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 137/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0091 - accuracy: 0.6512 - val_loss: 0.4574 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 138/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0091 - accuracy: 0.6395 - val_loss: 0.4652 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 139/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0092 - accuracy: 0.6494 - val_loss: 0.4639 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 140/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0091 - accuracy: 0.6430 - val_loss: 0.4653 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 141/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0090 - accuracy: 0.6436 - val_loss: 0.4618 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 142/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0091 - accuracy: 0.6583 - val_loss: 0.4542 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 143/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0090 - accuracy: 0.6418 - val_loss: 0.4535 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 144/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0090 - accuracy: 0.6312 - val_loss: 0.4610 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 145/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0092 - accuracy: 0.6353 - val_loss: 0.4592 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 146/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0092 - accuracy: 0.6430 - val_loss: 0.4598 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 147/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0092 - accuracy: 0.6371 - val_loss: 0.4627 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 148/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0091 - accuracy: 0.6571 - val_loss: 0.4572 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 149/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0090 - accuracy: 0.6770 - val_loss: 0.4555 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 150/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0091 - accuracy: 0.6618 - val_loss: 0.4554 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 151/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0091 - accuracy: 0.6471 - val_loss: 0.4484 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 152/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0091 - accuracy: 0.6430 - val_loss: 0.4584 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 153/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0090 - accuracy: 0.6629 - val_loss: 0.4579 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 154/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0090 - accuracy: 0.6465 - val_loss: 0.4523 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 155/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0090 - accuracy: 0.6430 - val_loss: 0.4544 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 156/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0090 - accuracy: 0.6583 - val_loss: 0.4545 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 157/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0090 - accuracy: 0.6577 - val_loss: 0.4599 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 158/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0090 - accuracy: 0.6583 - val_loss: 0.4504 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 159/1000\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 0.0091 - accuracy: 0.6577 - val_loss: 0.4433 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 160/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0089 - accuracy: 0.6600 - val_loss: 0.4422 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 161/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0090 - accuracy: 0.6518 - val_loss: 0.4455 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 162/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0090 - accuracy: 0.6471 - val_loss: 0.4534 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 163/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0090 - accuracy: 0.6606 - val_loss: 0.4508 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 164/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0090 - accuracy: 0.6494 - val_loss: 0.4499 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 165/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0090 - accuracy: 0.6547 - val_loss: 0.4421 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 166/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0090 - accuracy: 0.6477 - val_loss: 0.4456 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 167/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0090 - accuracy: 0.6676 - val_loss: 0.4493 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 168/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0091 - accuracy: 0.6430 - val_loss: 0.4438 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 169/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0089 - accuracy: 0.6547 - val_loss: 0.4409 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 170/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0090 - accuracy: 0.6583 - val_loss: 0.4399 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 171/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0090 - accuracy: 0.6671 - val_loss: 0.4505 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 172/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0090 - accuracy: 0.6447 - val_loss: 0.4498 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 173/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0090 - accuracy: 0.6412 - val_loss: 0.4437 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 174/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0090 - accuracy: 0.6524 - val_loss: 0.4476 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 175/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0089 - accuracy: 0.6706 - val_loss: 0.4386 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 176/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0090 - accuracy: 0.6577 - val_loss: 0.4437 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 177/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0088 - accuracy: 0.6694 - val_loss: 0.4311 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 178/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0089 - accuracy: 0.6559 - val_loss: 0.4410 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 179/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0089 - accuracy: 0.6447 - val_loss: 0.4406 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 180/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0090 - accuracy: 0.6430 - val_loss: 0.4412 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 181/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0089 - accuracy: 0.6776 - val_loss: 0.4290 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 182/1000\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 0.0089 - accuracy: 0.6547 - val_loss: 0.4330 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 183/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0089 - accuracy: 0.6512 - val_loss: 0.4390 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 184/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0088 - accuracy: 0.6776 - val_loss: 0.4312 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 185/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0089 - accuracy: 0.6635 - val_loss: 0.4335 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 186/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0089 - accuracy: 0.6665 - val_loss: 0.4362 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 187/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0089 - accuracy: 0.6541 - val_loss: 0.4288 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 188/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0089 - accuracy: 0.6600 - val_loss: 0.4292 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 189/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0089 - accuracy: 0.6624 - val_loss: 0.4310 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 190/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0090 - accuracy: 0.6489 - val_loss: 0.4265 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 191/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0089 - accuracy: 0.6606 - val_loss: 0.4321 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 192/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0089 - accuracy: 0.6477 - val_loss: 0.4340 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 193/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0088 - accuracy: 0.6729 - val_loss: 0.4292 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 194/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0088 - accuracy: 0.6530 - val_loss: 0.4274 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 195/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0088 - accuracy: 0.6436 - val_loss: 0.4298 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 196/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0089 - accuracy: 0.6500 - val_loss: 0.4295 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 197/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0088 - accuracy: 0.6530 - val_loss: 0.4283 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 198/1000\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 0.0089 - accuracy: 0.6671 - val_loss: 0.4222 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 199/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0088 - accuracy: 0.6530 - val_loss: 0.4250 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 200/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0088 - accuracy: 0.6682 - val_loss: 0.4271 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 201/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0089 - accuracy: 0.6524 - val_loss: 0.4247 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 202/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.6518 - val_loss: 0.4259 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 203/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0088 - accuracy: 0.6518 - val_loss: 0.4231 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 204/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0088 - accuracy: 0.6817 - val_loss: 0.4253 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 205/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0089 - accuracy: 0.6588 - val_loss: 0.4224 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 206/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0088 - accuracy: 0.6465 - val_loss: 0.4165 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 207/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0088 - accuracy: 0.6471 - val_loss: 0.4206 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 208/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0088 - accuracy: 0.6571 - val_loss: 0.4266 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 209/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0089 - accuracy: 0.6606 - val_loss: 0.4276 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 210/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0088 - accuracy: 0.6553 - val_loss: 0.4241 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 211/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0089 - accuracy: 0.6365 - val_loss: 0.4249 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 212/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.6524 - val_loss: 0.4305 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 213/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0088 - accuracy: 0.6536 - val_loss: 0.4225 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 214/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0088 - accuracy: 0.6571 - val_loss: 0.4233 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 215/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0088 - accuracy: 0.6641 - val_loss: 0.4152 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 216/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0087 - accuracy: 0.6653 - val_loss: 0.4075 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 217/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.6324 - val_loss: 0.4170 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 218/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0088 - accuracy: 0.6600 - val_loss: 0.4237 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 219/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0088 - accuracy: 0.6618 - val_loss: 0.4266 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 220/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0088 - accuracy: 0.6371 - val_loss: 0.4280 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 221/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0088 - accuracy: 0.6618 - val_loss: 0.4202 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 222/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.6577 - val_loss: 0.4189 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 223/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0088 - accuracy: 0.6553 - val_loss: 0.4129 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 224/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0088 - accuracy: 0.6641 - val_loss: 0.4220 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 225/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0088 - accuracy: 0.6706 - val_loss: 0.4123 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 226/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.6653 - val_loss: 0.4196 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 227/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0088 - accuracy: 0.6553 - val_loss: 0.4161 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 228/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0088 - accuracy: 0.6547 - val_loss: 0.4205 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 229/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0088 - accuracy: 0.6524 - val_loss: 0.4291 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 230/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0087 - accuracy: 0.6512 - val_loss: 0.4143 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 231/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.6618 - val_loss: 0.4180 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 232/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0088 - accuracy: 0.6688 - val_loss: 0.4258 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 233/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.6442 - val_loss: 0.4174 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 234/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.6729 - val_loss: 0.4202 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 235/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.6606 - val_loss: 0.4182 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 236/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0088 - accuracy: 0.6530 - val_loss: 0.4205 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 237/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.6624 - val_loss: 0.4236 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 238/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0087 - accuracy: 0.6412 - val_loss: 0.4181 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 239/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0086 - accuracy: 0.6547 - val_loss: 0.4061 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 240/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0087 - accuracy: 0.6858 - val_loss: 0.3977 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 241/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.6459 - val_loss: 0.4004 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 242/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0087 - accuracy: 0.6324 - val_loss: 0.4004 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 243/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.6647 - val_loss: 0.4070 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 244/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.6442 - val_loss: 0.4045 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 245/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.6447 - val_loss: 0.4091 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 246/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.6594 - val_loss: 0.4152 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 247/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.6588 - val_loss: 0.4123 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 248/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.6547 - val_loss: 0.4101 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 249/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.6524 - val_loss: 0.4051 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 250/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.6653 - val_loss: 0.4176 - val_accuracy: 0.8718 - lr: 0.0010\n",
      "Epoch 251/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.6289 - val_loss: 0.4048 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 252/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.6524 - val_loss: 0.4063 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 253/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0087 - accuracy: 0.6665 - val_loss: 0.3973 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 254/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.6430 - val_loss: 0.4224 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 255/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.6365 - val_loss: 0.4113 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 256/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0087 - accuracy: 0.6506 - val_loss: 0.4007 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 257/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0087 - accuracy: 0.6442 - val_loss: 0.4051 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 258/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.6483 - val_loss: 0.4156 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 259/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.6536 - val_loss: 0.4045 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 260/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.6483 - val_loss: 0.4058 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 261/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.6453 - val_loss: 0.4089 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 262/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.6547 - val_loss: 0.4018 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 263/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.6359 - val_loss: 0.3991 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 264/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.6471 - val_loss: 0.4072 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 265/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.6489 - val_loss: 0.4005 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 266/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0086 - accuracy: 0.6424 - val_loss: 0.3955 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 267/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0086 - accuracy: 0.6571 - val_loss: 0.3940 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 268/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0086 - accuracy: 0.6518 - val_loss: 0.3977 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 269/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.6500 - val_loss: 0.4048 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 270/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.6477 - val_loss: 0.4018 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 271/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.6577 - val_loss: 0.4043 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 272/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.6641 - val_loss: 0.4071 - val_accuracy: 0.8718 - lr: 0.0010\n",
      "Epoch 273/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.6553 - val_loss: 0.4045 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 274/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.6500 - val_loss: 0.4041 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 275/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.6541 - val_loss: 0.3969 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 276/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.6635 - val_loss: 0.3985 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 277/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.6577 - val_loss: 0.4097 - val_accuracy: 0.8718 - lr: 0.0010\n",
      "Epoch 278/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.6383 - val_loss: 0.4114 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 279/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.6483 - val_loss: 0.4005 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 280/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.6559 - val_loss: 0.3976 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 281/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0086 - accuracy: 0.6571 - val_loss: 0.4115 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 282/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0085 - accuracy: 0.6524 - val_loss: 0.4126 - val_accuracy: 0.8718 - lr: 0.0010\n",
      "Epoch 283/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.6489 - val_loss: 0.4028 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 284/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.6436 - val_loss: 0.4077 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 285/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0086 - accuracy: 0.6536 - val_loss: 0.4015 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 286/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.6641 - val_loss: 0.4010 - val_accuracy: 0.8718 - lr: 0.0010\n",
      "Epoch 287/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.6583 - val_loss: 0.4036 - val_accuracy: 0.8718 - lr: 0.0010\n",
      "Epoch 288/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.6553 - val_loss: 0.3978 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 289/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0086 - accuracy: 0.6494 - val_loss: 0.4005 - val_accuracy: 0.8686 - lr: 0.0010\n",
      "Epoch 290/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.6483 - val_loss: 0.3960 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 291/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.6671 - val_loss: 0.4033 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 292/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0085 - accuracy: 0.6618 - val_loss: 0.3897 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 293/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0087 - accuracy: 0.6536 - val_loss: 0.3968 - val_accuracy: 0.8718 - lr: 0.0010\n",
      "Epoch 294/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.6706 - val_loss: 0.4015 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 295/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.6541 - val_loss: 0.3951 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 296/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.6447 - val_loss: 0.4014 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 297/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.6565 - val_loss: 0.3954 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 298/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.6471 - val_loss: 0.4012 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 299/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.6406 - val_loss: 0.4012 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 300/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.6665 - val_loss: 0.3960 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 301/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.6577 - val_loss: 0.3912 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 302/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.6453 - val_loss: 0.3901 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 303/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.6500 - val_loss: 0.3982 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 304/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0085 - accuracy: 0.6447 - val_loss: 0.3870 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 305/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.6418 - val_loss: 0.3926 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 306/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0085 - accuracy: 0.6412 - val_loss: 0.3941 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 307/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.6336 - val_loss: 0.3892 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 308/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.6735 - val_loss: 0.3997 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 309/1000\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 0.0086 - accuracy: 0.6412 - val_loss: 0.3857 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 310/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0087 - accuracy: 0.6412 - val_loss: 0.3885 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 311/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0086 - accuracy: 0.6377 - val_loss: 0.3787 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 312/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.6459 - val_loss: 0.3871 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 313/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.6330 - val_loss: 0.3867 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 314/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6400 - val_loss: 0.3903 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 315/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.6547 - val_loss: 0.3803 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 316/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.6483 - val_loss: 0.3813 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 317/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.6553 - val_loss: 0.3867 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 318/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0086 - accuracy: 0.6512 - val_loss: 0.3909 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 319/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6565 - val_loss: 0.3789 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 320/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.6530 - val_loss: 0.3833 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 321/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0086 - accuracy: 0.6477 - val_loss: 0.3852 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 322/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6524 - val_loss: 0.3829 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 323/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6242 - val_loss: 0.3878 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 324/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.6541 - val_loss: 0.3844 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 325/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6559 - val_loss: 0.3923 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 326/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.6547 - val_loss: 0.3886 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 327/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0085 - accuracy: 0.6571 - val_loss: 0.3781 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 328/1000\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 0.0084 - accuracy: 0.6553 - val_loss: 0.3778 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 329/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6453 - val_loss: 0.3795 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 330/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.6618 - val_loss: 0.3870 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 331/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.6459 - val_loss: 0.3843 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 332/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0085 - accuracy: 0.6494 - val_loss: 0.3908 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 333/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0085 - accuracy: 0.6289 - val_loss: 0.3742 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 334/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0085 - accuracy: 0.6307 - val_loss: 0.3835 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 335/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.6424 - val_loss: 0.3835 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 336/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0084 - accuracy: 0.6436 - val_loss: 0.3784 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 337/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6436 - val_loss: 0.3775 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 338/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.6565 - val_loss: 0.3745 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 339/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6512 - val_loss: 0.3838 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 340/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6547 - val_loss: 0.3744 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 341/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0084 - accuracy: 0.6553 - val_loss: 0.3720 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 342/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0085 - accuracy: 0.6459 - val_loss: 0.3718 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 343/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0085 - accuracy: 0.6477 - val_loss: 0.3835 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 344/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0084 - accuracy: 0.6600 - val_loss: 0.3811 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 345/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0084 - accuracy: 0.6459 - val_loss: 0.3700 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 346/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.6536 - val_loss: 0.3811 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 347/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.6500 - val_loss: 0.3831 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 348/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6389 - val_loss: 0.3795 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 349/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.6348 - val_loss: 0.3717 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 350/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6447 - val_loss: 0.3774 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 351/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.6447 - val_loss: 0.3749 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 352/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6571 - val_loss: 0.3740 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 353/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6518 - val_loss: 0.3799 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 354/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6371 - val_loss: 0.3731 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 355/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6530 - val_loss: 0.3792 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 356/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6353 - val_loss: 0.3757 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 357/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0084 - accuracy: 0.6524 - val_loss: 0.3691 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 358/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.6459 - val_loss: 0.3698 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 359/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.6530 - val_loss: 0.3795 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 360/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6436 - val_loss: 0.3719 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 361/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0084 - accuracy: 0.6436 - val_loss: 0.3660 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 362/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0084 - accuracy: 0.6518 - val_loss: 0.3697 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 363/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6594 - val_loss: 0.3675 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 364/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0084 - accuracy: 0.6483 - val_loss: 0.3784 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 365/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6489 - val_loss: 0.3738 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 366/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6459 - val_loss: 0.3689 - val_accuracy: 0.9071 - lr: 0.0010\n",
      "Epoch 367/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6465 - val_loss: 0.3741 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 368/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6530 - val_loss: 0.3765 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 369/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6424 - val_loss: 0.3687 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 370/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0085 - accuracy: 0.6442 - val_loss: 0.3745 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 371/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6453 - val_loss: 0.3666 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 372/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6500 - val_loss: 0.3681 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 373/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0083 - accuracy: 0.6682 - val_loss: 0.3581 - val_accuracy: 0.9071 - lr: 0.0010\n",
      "Epoch 374/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0084 - accuracy: 0.6453 - val_loss: 0.3693 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 375/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6265 - val_loss: 0.3807 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 376/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6500 - val_loss: 0.3746 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 377/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6377 - val_loss: 0.3688 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 378/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6577 - val_loss: 0.3679 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 379/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6442 - val_loss: 0.3704 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 380/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6424 - val_loss: 0.3662 - val_accuracy: 0.9071 - lr: 0.0010\n",
      "Epoch 381/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6541 - val_loss: 0.3733 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 382/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6500 - val_loss: 0.3671 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 383/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6359 - val_loss: 0.3734 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 384/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6588 - val_loss: 0.3721 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 385/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6442 - val_loss: 0.3662 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 386/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6430 - val_loss: 0.3845 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 387/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6688 - val_loss: 0.3693 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 388/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0084 - accuracy: 0.6312 - val_loss: 0.3572 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 389/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0083 - accuracy: 0.6506 - val_loss: 0.3710 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 390/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6459 - val_loss: 0.3683 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 391/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6412 - val_loss: 0.3626 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 392/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0083 - accuracy: 0.6353 - val_loss: 0.3708 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 393/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6700 - val_loss: 0.3758 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 394/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6295 - val_loss: 0.3687 - val_accuracy: 0.8814 - lr: 0.0010\n",
      "Epoch 395/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6324 - val_loss: 0.3721 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 396/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6571 - val_loss: 0.3600 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 397/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0083 - accuracy: 0.6471 - val_loss: 0.3567 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 398/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6506 - val_loss: 0.3657 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 399/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6530 - val_loss: 0.3659 - val_accuracy: 0.9071 - lr: 0.0010\n",
      "Epoch 400/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0083 - accuracy: 0.6371 - val_loss: 0.3592 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 401/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6553 - val_loss: 0.3584 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 402/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6536 - val_loss: 0.3578 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 403/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6436 - val_loss: 0.3709 - val_accuracy: 0.9071 - lr: 0.0010\n",
      "Epoch 404/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6406 - val_loss: 0.3631 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 405/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6518 - val_loss: 0.3629 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 406/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6400 - val_loss: 0.3632 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 407/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6506 - val_loss: 0.3603 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 408/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0084 - accuracy: 0.6483 - val_loss: 0.3672 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 409/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6436 - val_loss: 0.3704 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 410/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6442 - val_loss: 0.3644 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 411/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6389 - val_loss: 0.3669 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 412/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6477 - val_loss: 0.3587 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 413/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6530 - val_loss: 0.3706 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 414/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6365 - val_loss: 0.3670 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 415/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6348 - val_loss: 0.3625 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 416/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6459 - val_loss: 0.3615 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 417/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0082 - accuracy: 0.6324 - val_loss: 0.3555 - val_accuracy: 0.9103 - lr: 0.0010\n",
      "Epoch 418/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6536 - val_loss: 0.3633 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 419/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6424 - val_loss: 0.3606 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 420/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6430 - val_loss: 0.3566 - val_accuracy: 0.9103 - lr: 0.0010\n",
      "Epoch 421/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6406 - val_loss: 0.3595 - val_accuracy: 0.9103 - lr: 0.0010\n",
      "Epoch 422/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6283 - val_loss: 0.3637 - val_accuracy: 0.9071 - lr: 0.0010\n",
      "Epoch 423/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6500 - val_loss: 0.3641 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 424/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6400 - val_loss: 0.3709 - val_accuracy: 0.8846 - lr: 0.0010\n",
      "Epoch 425/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6359 - val_loss: 0.3642 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 426/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6359 - val_loss: 0.3656 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 427/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6483 - val_loss: 0.3603 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 428/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6365 - val_loss: 0.3592 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 429/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6553 - val_loss: 0.3612 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 430/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6400 - val_loss: 0.3573 - val_accuracy: 0.9071 - lr: 0.0010\n",
      "Epoch 431/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6336 - val_loss: 0.3557 - val_accuracy: 0.9135 - lr: 0.0010\n",
      "Epoch 432/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0083 - accuracy: 0.6383 - val_loss: 0.3564 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 433/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0083 - accuracy: 0.6459 - val_loss: 0.3488 - val_accuracy: 0.9135 - lr: 0.0010\n",
      "Epoch 434/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6500 - val_loss: 0.3557 - val_accuracy: 0.9071 - lr: 0.0010\n",
      "Epoch 435/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6289 - val_loss: 0.3581 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 436/1000\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0083 - accuracy: 0.6500 - val_loss: 0.3578 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 437/1000\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0083 - accuracy: 0.6442 - val_loss: 0.3494 - val_accuracy: 0.9071 - lr: 0.0010\n",
      "Epoch 438/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6465 - val_loss: 0.3581 - val_accuracy: 0.9103 - lr: 0.0010\n",
      "Epoch 439/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6348 - val_loss: 0.3652 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 440/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6500 - val_loss: 0.3530 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 441/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6277 - val_loss: 0.3489 - val_accuracy: 0.9071 - lr: 0.0010\n",
      "Epoch 442/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6489 - val_loss: 0.3562 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 443/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6330 - val_loss: 0.3537 - val_accuracy: 0.9103 - lr: 0.0010\n",
      "Epoch 444/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6494 - val_loss: 0.3586 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 445/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6359 - val_loss: 0.3512 - val_accuracy: 0.9103 - lr: 0.0010\n",
      "Epoch 446/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6500 - val_loss: 0.3517 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 447/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0083 - accuracy: 0.6512 - val_loss: 0.3408 - val_accuracy: 0.9071 - lr: 0.0010\n",
      "Epoch 448/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6342 - val_loss: 0.3550 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 449/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0082 - accuracy: 0.6442 - val_loss: 0.3592 - val_accuracy: 0.9103 - lr: 0.0010\n",
      "Epoch 450/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6471 - val_loss: 0.3559 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 451/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6465 - val_loss: 0.3463 - val_accuracy: 0.9071 - lr: 0.0010\n",
      "Epoch 452/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6500 - val_loss: 0.3535 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 453/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6330 - val_loss: 0.3607 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 454/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6307 - val_loss: 0.3487 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 455/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6436 - val_loss: 0.3618 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 456/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6530 - val_loss: 0.3562 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 457/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6436 - val_loss: 0.3475 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 458/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6447 - val_loss: 0.3507 - val_accuracy: 0.9135 - lr: 0.0010\n",
      "Epoch 459/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0084 - accuracy: 0.6336 - val_loss: 0.3552 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 460/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6442 - val_loss: 0.3540 - val_accuracy: 0.9071 - lr: 0.0010\n",
      "Epoch 461/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6424 - val_loss: 0.3554 - val_accuracy: 0.9071 - lr: 0.0010\n",
      "Epoch 462/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6295 - val_loss: 0.3564 - val_accuracy: 0.9071 - lr: 0.0010\n",
      "Epoch 463/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6459 - val_loss: 0.3545 - val_accuracy: 0.9103 - lr: 0.0010\n",
      "Epoch 464/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6547 - val_loss: 0.3522 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 465/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6447 - val_loss: 0.3430 - val_accuracy: 0.9103 - lr: 0.0010\n",
      "Epoch 466/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6471 - val_loss: 0.3514 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 467/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6471 - val_loss: 0.3525 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 468/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6371 - val_loss: 0.3459 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 469/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6430 - val_loss: 0.3506 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 470/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6330 - val_loss: 0.3582 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 471/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6453 - val_loss: 0.3520 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 472/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0082 - accuracy: 0.6342 - val_loss: 0.3519 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 473/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6483 - val_loss: 0.3518 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 474/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6489 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 0.0010\n",
      "Epoch 475/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6453 - val_loss: 0.3538 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 476/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6348 - val_loss: 0.3565 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 477/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6307 - val_loss: 0.3506 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 478/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6371 - val_loss: 0.3625 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 479/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6430 - val_loss: 0.3500 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 480/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6330 - val_loss: 0.3489 - val_accuracy: 0.9071 - lr: 0.0010\n",
      "Epoch 481/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6365 - val_loss: 0.3515 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 482/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0083 - accuracy: 0.6471 - val_loss: 0.3526 - val_accuracy: 0.8974 - lr: 0.0010\n",
      "Epoch 483/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6406 - val_loss: 0.3511 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 484/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6424 - val_loss: 0.3469 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 485/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6536 - val_loss: 0.3571 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 486/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6471 - val_loss: 0.3544 - val_accuracy: 0.9071 - lr: 0.0010\n",
      "Epoch 487/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6236 - val_loss: 0.3470 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 488/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6312 - val_loss: 0.3591 - val_accuracy: 0.8942 - lr: 0.0010\n",
      "Epoch 489/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6418 - val_loss: 0.3605 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 490/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6442 - val_loss: 0.3514 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 491/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6436 - val_loss: 0.3439 - val_accuracy: 0.9135 - lr: 0.0010\n",
      "Epoch 492/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6324 - val_loss: 0.3521 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 493/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0082 - accuracy: 0.6489 - val_loss: 0.3535 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 494/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0082 - accuracy: 0.6371 - val_loss: 0.3529 - val_accuracy: 0.9038 - lr: 0.0010\n",
      "Epoch 495/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6395 - val_loss: 0.3474 - val_accuracy: 0.9071 - lr: 0.0010\n",
      "Epoch 496/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6254 - val_loss: 0.3497 - val_accuracy: 0.9071 - lr: 0.0010\n",
      "Epoch 497/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6389 - val_loss: 0.3546 - val_accuracy: 0.9006 - lr: 0.0010\n",
      "Epoch 498/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6412 - val_loss: 0.3543 - val_accuracy: 0.9038 - lr: 1.0000e-04\n",
      "Epoch 499/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6436 - val_loss: 0.3533 - val_accuracy: 0.9038 - lr: 1.0000e-04\n",
      "Epoch 500/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0081 - accuracy: 0.6442 - val_loss: 0.3532 - val_accuracy: 0.9038 - lr: 1.0000e-04\n",
      "Epoch 501/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6477 - val_loss: 0.3528 - val_accuracy: 0.9006 - lr: 1.0000e-04\n",
      "Epoch 502/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6371 - val_loss: 0.3505 - val_accuracy: 0.9038 - lr: 1.0000e-04\n",
      "Epoch 503/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0082 - accuracy: 0.6430 - val_loss: 0.3503 - val_accuracy: 0.9006 - lr: 1.0000e-04\n",
      "Epoch 504/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6494 - val_loss: 0.3502 - val_accuracy: 0.9006 - lr: 1.0000e-04\n",
      "Epoch 505/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6506 - val_loss: 0.3500 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 506/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6318 - val_loss: 0.3510 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 507/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6524 - val_loss: 0.3519 - val_accuracy: 0.9006 - lr: 1.0000e-04\n",
      "Epoch 508/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6424 - val_loss: 0.3513 - val_accuracy: 0.9038 - lr: 1.0000e-04\n",
      "Epoch 509/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6447 - val_loss: 0.3493 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 510/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6430 - val_loss: 0.3485 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 511/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6430 - val_loss: 0.3486 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 512/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0081 - accuracy: 0.6412 - val_loss: 0.3484 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 513/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6471 - val_loss: 0.3476 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 514/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6412 - val_loss: 0.3481 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 515/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0082 - accuracy: 0.6406 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 516/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6430 - val_loss: 0.3485 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 517/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6377 - val_loss: 0.3483 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 518/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6365 - val_loss: 0.3483 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 519/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6389 - val_loss: 0.3499 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 520/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6436 - val_loss: 0.3499 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 521/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6465 - val_loss: 0.3497 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 522/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6395 - val_loss: 0.3483 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 523/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6418 - val_loss: 0.3479 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 524/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6359 - val_loss: 0.3479 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 525/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6477 - val_loss: 0.3477 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 526/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6389 - val_loss: 0.3471 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 527/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6447 - val_loss: 0.3487 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 528/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6453 - val_loss: 0.3495 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 529/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6447 - val_loss: 0.3506 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 530/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0081 - accuracy: 0.6453 - val_loss: 0.3511 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 531/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6436 - val_loss: 0.3513 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 532/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6471 - val_loss: 0.3517 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 533/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6477 - val_loss: 0.3505 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 534/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0082 - accuracy: 0.6412 - val_loss: 0.3498 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 535/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6406 - val_loss: 0.3490 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 536/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6494 - val_loss: 0.3487 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 537/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6395 - val_loss: 0.3493 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 538/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6483 - val_loss: 0.3483 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 539/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6395 - val_loss: 0.3484 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 540/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6342 - val_loss: 0.3494 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 541/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6418 - val_loss: 0.3490 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 542/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6312 - val_loss: 0.3491 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 543/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6406 - val_loss: 0.3489 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 544/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6442 - val_loss: 0.3495 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 545/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6453 - val_loss: 0.3494 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 546/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6465 - val_loss: 0.3492 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 547/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6459 - val_loss: 0.3483 - val_accuracy: 0.9071 - lr: 1.0000e-04\n",
      "Epoch 548/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6424 - val_loss: 0.3485 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 549/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6453 - val_loss: 0.3486 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 550/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6383 - val_loss: 0.3486 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 551/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6442 - val_loss: 0.3485 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 552/1000\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0081 - accuracy: 0.6453 - val_loss: 0.3484 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 553/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6459 - val_loss: 0.3483 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 554/1000\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0081 - accuracy: 0.6453 - val_loss: 0.3482 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 555/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6383 - val_loss: 0.3482 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 556/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6400 - val_loss: 0.3482 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 557/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0081 - accuracy: 0.6412 - val_loss: 0.3481 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 558/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6424 - val_loss: 0.3482 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 559/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6436 - val_loss: 0.3482 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 560/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6447 - val_loss: 0.3482 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 561/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6436 - val_loss: 0.3481 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 562/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6418 - val_loss: 0.3481 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 563/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6424 - val_loss: 0.3481 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 564/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6442 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 565/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6465 - val_loss: 0.3481 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 566/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6395 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 567/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6353 - val_loss: 0.3482 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 568/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6353 - val_loss: 0.3483 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 569/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6359 - val_loss: 0.3483 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 570/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6371 - val_loss: 0.3485 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 571/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6412 - val_loss: 0.3485 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 572/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6371 - val_loss: 0.3485 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 573/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6465 - val_loss: 0.3486 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 574/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6365 - val_loss: 0.3486 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 575/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6400 - val_loss: 0.3487 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 576/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6442 - val_loss: 0.3487 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 577/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0081 - accuracy: 0.6442 - val_loss: 0.3487 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 578/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0081 - accuracy: 0.6447 - val_loss: 0.3489 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 579/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6301 - val_loss: 0.3488 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 580/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6389 - val_loss: 0.3489 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 581/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6395 - val_loss: 0.3490 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 582/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6430 - val_loss: 0.3491 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 583/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0081 - accuracy: 0.6447 - val_loss: 0.3491 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 584/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6377 - val_loss: 0.3490 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 585/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6447 - val_loss: 0.3489 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 586/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0081 - accuracy: 0.6412 - val_loss: 0.3488 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 587/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0081 - accuracy: 0.6442 - val_loss: 0.3487 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 588/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0080 - accuracy: 0.6442 - val_loss: 0.3488 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 589/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6459 - val_loss: 0.3488 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 590/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6465 - val_loss: 0.3486 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 591/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0082 - accuracy: 0.6348 - val_loss: 0.3483 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 592/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6418 - val_loss: 0.3482 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 593/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6395 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 594/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6365 - val_loss: 0.3479 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 595/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0081 - accuracy: 0.6447 - val_loss: 0.3479 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 596/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6418 - val_loss: 0.3479 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 597/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0082 - accuracy: 0.6442 - val_loss: 0.3479 - val_accuracy: 0.9071 - lr: 1.0000e-05\n",
      "Epoch 598/1000\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 0.0082 - accuracy: 0.6424 - val_loss: 0.3479 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 599/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0081 - accuracy: 0.6436 - val_loss: 0.3479 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 600/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0081 - accuracy: 0.6453 - val_loss: 0.3479 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 601/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0082 - accuracy: 0.6453 - val_loss: 0.3479 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 602/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0081 - accuracy: 0.6424 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 603/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0082 - accuracy: 0.6400 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 604/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0082 - accuracy: 0.6436 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 605/1000\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 0.0082 - accuracy: 0.6406 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 606/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6412 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 607/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6377 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 608/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6489 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 609/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6395 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 610/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6383 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 611/1000\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0082 - accuracy: 0.6377 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 612/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6447 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 613/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6471 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 614/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6395 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 615/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6453 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 616/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6406 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 617/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6389 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 618/1000\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0081 - accuracy: 0.6412 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 619/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6436 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 620/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6377 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 621/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6430 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 622/1000\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0081 - accuracy: 0.6424 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 623/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6389 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 624/1000\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0081 - accuracy: 0.6348 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 625/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6453 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 626/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6395 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 627/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6389 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 628/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6430 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 629/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6447 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 630/1000\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0081 - accuracy: 0.6453 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 631/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6524 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 632/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6389 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 633/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0080 - accuracy: 0.6412 - val_loss: 0.3480 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 634/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6477 - val_loss: 0.3481 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 635/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6395 - val_loss: 0.3481 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 636/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6465 - val_loss: 0.3481 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 637/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6389 - val_loss: 0.3481 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 638/1000\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0081 - accuracy: 0.6430 - val_loss: 0.3481 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 639/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6494 - val_loss: 0.3481 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 640/1000\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 0.0081 - accuracy: 0.6406 - val_loss: 0.3481 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 641/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6383 - val_loss: 0.3481 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 642/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6418 - val_loss: 0.3481 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 643/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.6442 - val_loss: 0.3481 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 644/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6447 - val_loss: 0.3481 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 645/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0082 - accuracy: 0.6383 - val_loss: 0.3481 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 646/1000\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 0.0080 - accuracy: 0.6447 - val_loss: 0.3481 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Epoch 647/1000\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 0.0083 - accuracy: 0.6348 - val_loss: 0.3481 - val_accuracy: 0.9071 - lr: 1.0000e-06\n",
      "Training time: 121.48288607597351 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Train the model\n",
    "def train_network(model, train_x, train_y, test_x, test_y):\n",
    "    verbose = 1 # 0 for no logging to stdout, 1 for progress bar logging, 2 for one log line per epoch.\n",
    "    epochs = 1000\n",
    "    batch_size = 128\n",
    "    model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, validation_data=(test_x, test_y), class_weight = class_weights, callbacks = [model_checkpoint_callback, reduce_lr, early_stopping], verbose=verbose)\n",
    "    _, accuracy = model.evaluate(test_x, test_y, batch_size=batch_size, verbose=0)\n",
    "    return model\n",
    "\n",
    "start_time = time.time()\n",
    "model = train_network(model, train_x, train_y, test_x, test_y)\n",
    "print(\"Training time: %s seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of filtered prediction: 0.7019230769230769\n",
      "Highest false confidence: 0.86824876\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9954337899543378\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "highest_false_confidence = 0\n",
    "\n",
    "# model.load_weights(checkpoint_filepath)\n",
    "y_prediction = model.predict(test_x)\n",
    "\n",
    "threshold = 0.7\n",
    "# remove all the prediction with probability less than threshold\n",
    "filtered_pred = []\n",
    "filtered_test = []\n",
    "for i in range(len(y_prediction)):\n",
    "    if np.max(y_prediction[i]) > threshold:\n",
    "        filtered_pred.append(np.argmax(y_prediction[i]))\n",
    "        filtered_test.append(np.argmax(test_y[i]))\n",
    "        if np.max(y_prediction[i]) > highest_false_confidence and np.argmax(y_prediction[i]) != np.argmax(test_y[i]):\n",
    "            highest_false_confidence = np.max(y_prediction[i])\n",
    "\n",
    "# print proportion of filtered prediction\n",
    "print(\"Proportion of filtered prediction: \" + str(len(filtered_pred)/len(y_prediction)))\n",
    "\n",
    "# print highest false confidence\n",
    "print(\"Highest false confidence: \" + str(highest_false_confidence))\n",
    "\n",
    "result = confusion_matrix(filtered_test, filtered_pred)\n",
    "\n",
    "# result = confusion_matrix(np.argmax(test_y, axis=1), y_prediction)\n",
    "sns.heatmap(result, annot=True, fmt=\"d\", xticklabels=action_types, yticklabels=action_types)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# print accuracy\n",
    "print(\"Accuracy: \" + str(np.sum(np.diag(result))/np.sum(result)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction ended at window 201\n",
      "best prob: 0.7348029\n",
      "prediction ended at window 32\n",
      "best prob: 0.7071132\n",
      "prediction ended at window 41\n",
      "best prob: 0.70677644\n",
      "prediction ended at window 83\n",
      "best prob: 0.8626052\n",
      "prediction ended at window 81\n",
      "best prob: 0.72845685\n",
      "prediction ended at window 39\n",
      "best prob: 0.7313031\n",
      "prediction ended at window 91\n",
      "best prob: 0.71763873\n",
      "prediction ended at window 70\n",
      "best prob: 0.7051119\n",
      "prediction ended at window 34\n",
      "best prob: 0.727696\n",
      "prediction ended at window 62\n",
      "best prob: 0.7463812\n",
      "prediction ended at window 47\n",
      "best prob: 0.7318915\n",
      "prediction ended at window 48\n",
      "best prob: 0.7675914\n",
      "prediction ended at window 26\n",
      "best prob: 0.7074313\n",
      "prediction ended at window 115\n",
      "best prob: 0.71370137\n",
      "prediction ended at window 25\n",
      "best prob: 0.72678894\n",
      "prediction ended at window 31\n",
      "best prob: 0.71782637\n",
      "prediction ended at window 23\n",
      "best prob: 0.71840376\n",
      "prediction ended at window 41\n",
      "best prob: 0.71018445\n",
      "prediction ended at window 35\n",
      "best prob: 0.74578494\n",
      "prediction ended at window 207\n",
      "best prob: 0.7327732\n",
      "prediction ended at window 47\n",
      "best prob: 0.72004724\n",
      "prediction ended at window 107\n",
      "best prob: 0.7080492\n",
      "prediction ended at window 68\n",
      "best prob: 0.71881163\n",
      "prediction ended at window 125\n",
      "best prob: 0.73107654\n",
      "prediction ended at window 69\n",
      "best prob: 0.7191072\n",
      "prediction ended at window 27\n",
      "best prob: 0.7378661\n",
      "prediction ended at window 34\n",
      "best prob: 0.7138343\n",
      "prediction ended at window 43\n",
      "best prob: 0.8291836\n",
      "prediction ended at window 41\n",
      "best prob: 0.70180655\n",
      "prediction ended at window 283\n",
      "best prob: 0.73973536\n",
      "prediction ended at window 35\n",
      "best prob: 0.7311857\n",
      "prediction ended at window 62\n",
      "best prob: 0.7084354\n",
      "prediction ended at window 34\n",
      "best prob: 0.72276694\n",
      "prediction ended at window 48\n",
      "best prob: 0.71005756\n",
      "prediction ended at window 54\n",
      "best prob: 0.7860595\n",
      "prediction ended at window 43\n",
      "best prob: 0.70677644\n",
      "prediction ended at window 46\n",
      "best prob: 0.7100756\n",
      "prediction ended at window 140\n",
      "best prob: 0.74372226\n",
      "prediction ended at window 99\n",
      "best prob: 0.7184237\n",
      "prediction ended at window 23\n",
      "best prob: 0.7289443\n",
      "prediction ended at window 45\n",
      "best prob: 0.76296157\n",
      "prediction ended at window 188\n",
      "best prob: 0.7326065\n",
      "prediction ended at window 52\n",
      "best prob: 0.7097566\n",
      "prediction ended at window 73\n",
      "best prob: 0.71370625\n",
      "prediction ended at window 62\n",
      "best prob: 0.74167067\n",
      "prediction ended at window 45\n",
      "best prob: 0.757334\n",
      "prediction ended at window 54\n",
      "best prob: 0.7425402\n",
      "prediction ended at window 49\n",
      "best prob: 0.7123818\n",
      "prediction ended at window 39\n",
      "best prob: 0.7066693\n",
      "prediction ended at window 37\n",
      "best prob: 0.7152028\n",
      "prediction ended at window 223\n",
      "best prob: 0.77728134\n",
      "prediction ended at window 49\n",
      "best prob: 0.7691267\n",
      "prediction ended at window 64\n",
      "best prob: 0.73079306\n",
      "prediction ended at window 65\n",
      "best prob: 0.80099964\n",
      "prediction ended at window 28\n",
      "best prob: 0.7253823\n",
      "prediction ended at window 112\n",
      "best prob: 0.7226433\n",
      "prediction ended at window 35\n",
      "best prob: 0.7091882\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Highest false confidence: 0.6454771\n"
     ]
    }
   ],
   "source": [
    "# evaluate actual performance\n",
    "pred = []\n",
    "actual = []\n",
    "highest_false_confidence = 0\n",
    "for i in range(len(test_x_eval)):\n",
    "    data = np.array(test_x_eval[i])\n",
    "    # sliding window until the prediction has probability greater than threshold, or end of the sequence and give the prediction with highest probability\n",
    "    best_pred, best_prob = 0, 0\n",
    "    for w in range(conv1kernel, len(data), conv1stride):\n",
    "        x = np.array(data[max(0, w-window_size):w])\n",
    "        x = np.concatenate((np.zeros((window_size - x.shape[0], 6)), x))\n",
    "        x = np.float32(x)/4096\n",
    "        y = model.predict(np.array([x]))\n",
    "        # print(f\"current window: {w}, prediction: {np.argmax(y)}, probability: {np.max(y)}, actual: {np.argmax(test_y_eval[i])}\")\n",
    "        if np.max(y) > highest_false_confidence and np.argmax(y) != np.argmax(test_y_eval[i]):\n",
    "            highest_false_confidence = np.max(y)\n",
    "        if np.max(y) > best_prob:\n",
    "            best_pred = np.argmax(y)\n",
    "            best_prob = np.max(y)\n",
    "        if np.max(y) > threshold:\n",
    "            print(\"prediction ended at window \" + str(w))\n",
    "            break\n",
    "    print(\"best prob: \", str(best_prob), \"w correct predict\" if best_pred == np.argmax(test_y_eval[i]) else \"w wrong predict\")\n",
    "    pred.append(best_pred)\n",
    "    actual.append(np.argmax(test_y_eval[i]))\n",
    "result = confusion_matrix(actual, pred)\n",
    "sns.heatmap(result, annot=True, fmt=\"d\", xticklabels=action_types, yticklabels=action_types)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# print accuracy\n",
    "print(\"Accuracy: \" + str(np.sum(np.diag(result))/np.sum(result)))\n",
    "\n",
    "# print highest false confidence\n",
    "print(\"Highest false confidence: \" + str(highest_false_confidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"window shape: {window_size, data_depth}\")\n",
    "print(f\"kernel shape: {conv1kernel, data_depth}\")\n",
    "print(f\"first layer weights shape: {model.layers[0].get_weights()[0].shape}\")\n",
    "print(f\"first layer output shape: {model.layers[0].output_shape}\")\n",
    "print(f\"second layer weights shape: {model.layers[3].get_weights()[0].shape}\")\n",
    "print(f\"second layer output shape: {model.layers[3].output_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out weights and biases one by one\n",
    "layers_indexes = [0, 3]\n",
    "\n",
    "for layer_index in layers_indexes:\n",
    "    layer = model.layers[layer_index]\n",
    "    layer_name = layer.name\n",
    "    weights = layer.get_weights()\n",
    "    print(weights[0].shape)\n",
    "    print(f\"INPUT_DTYPE model_param_{layer_name}_weights\")\n",
    "    for i in range(weights[0].shape[-1]):\n",
    "        print(\"index\", i)\n",
    "        print(np.transpose(np.transpose(weights[0])[i]))\n",
    "    print(f\"INPUT_DTYPE model_param_{layer_name}_biases\")\n",
    "    print(weights[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directly print out weights and biases\n",
    "layers_indexes = [0, 3]\n",
    "\n",
    "for layer_index in layers_indexes:\n",
    "    layer = model.layers[layer_index]\n",
    "    layer_name = layer.name\n",
    "    weights = layer.get_weights()\n",
    "    if layer_index == 0:\n",
    "        layer_name = \"CNN\"\n",
    "        weights_size_definition = \"[CNN_KERNEL_LENGTH][CNN_KERNEL_DEPTH][CNN_KERNEL_COUNT]\"\n",
    "        bias_size_definition = \"[CNN_KERNEL_COUNT]\"\n",
    "    else:\n",
    "        layer_name = \"dense\"\n",
    "        weights_size_definition = \"[DENSE_INPUT_NODES][DENSE_OUTPUT_NODES]\"\n",
    "        bias_size_definition = \"[DENSE_OUTPUT_NODES]\"\n",
    "    print(f\"static INPUT_DTYPE {layer_name}_weights{weights_size_definition} = {{\" + \", \".join([str(x) for x in weights[0].reshape(-1)]) + \"};\")\n",
    "    print(f\"static INPUT_DTYPE {layer_name}_bias{bias_size_definition} = {{\" + \", \".join([str(x) for x in weights[1]]) + \"};\")\n",
    "\n",
    "    # save weights and biases to file\n",
    "    np.save(f\"{layer_name}_weights.npy\", weights[0])\n",
    "    np.save(f\"{layer_name}_bias.npy\", weights[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directly print out test dataset\n",
    "n_values_per_line = 10\n",
    "dataset_size = len(test_x)\n",
    "# dataset_size = 1\n",
    "dataset_start_index = 0\n",
    "print(\"#define DATASET_SIZE\", dataset_size)\n",
    "\n",
    "# print out float test dataset\n",
    "print(f\"const float test_x[DATASET_SIZE][INPUT_LENGTH][INPUT_DEPTH] = {{\")\n",
    "for text_x_index in range(dataset_start_index, min(test_x.shape[0], dataset_start_index + dataset_size)):\n",
    "    for datapoint_index in range(0, len(test_x[text_x_index])):\n",
    "        for i in range(0, len(test_x[text_x_index][datapoint_index]), n_values_per_line):\n",
    "            print(\", \".join([str(x) for x in test_x_copy[text_x_index][datapoint_index][i:i+n_values_per_line]]) + \",\")\n",
    "print(\"};\") \n",
    "    \n",
    "print(f\"const int test_y[DATASET_SIZE][DENSE_OUTPUT_NODES] = {{\")\n",
    "for text_x_index in range(dataset_start_index, min(test_x.shape[0], dataset_start_index + dataset_size)):\n",
    "    for i in range(0, len(test_y[text_x_index]), n_values_per_line):\n",
    "        print(\", \".join([str(int(x)) for x in test_y[text_x_index][i:i+n_values_per_line]]) + \",\")\n",
    "print(\"};\")\n",
    "\n",
    "# save the test dataset\n",
    "np.save(\"test_x.npy\", test_x_copy)\n",
    "np.save(\"test_y.npy\", test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print model output without the last layer\n",
    "from keras.models import Model\n",
    "model_without_last_layer = Model(inputs=model.input, outputs=model.layers[-2].output)\n",
    "model_without_last_layer.summary()\n",
    "predicted_result = model_without_last_layer.predict(test_x)[0]\n",
    "print(predicted_result.shape)\n",
    "print(predicted_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('capstone')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f82d4ec2f4e1a7949fc551b5039d8b80c5fc6c2b366144cfac1fa6211cdc80ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
